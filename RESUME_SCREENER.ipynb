{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **skills_db.json content**"
      ],
      "metadata": {
        "id": "c_qThcjS9uuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"programming\": [\"python\", \"java\", \"javascript\", \"c++\", \"c#\", \"ruby\", \"php\", \"swift\", \"kotlin\", \"go\", \"rust\", \"typescript\"],\n",
        "  \"web_dev\": [\"html\", \"css\", \"react\", \"angular\", \"vue\", \"node.js\", \"django\", \"flask\", \"express\", \"fastapi\", \"spring\"],\n",
        "  \"databases\": [\"sql\", \"mysql\", \"postgresql\", \"mongodb\", \"oracle\", \"redis\", \"cassandra\", \"dynamodb\", \"sqlite\"],\n",
        "  \"ml_ai\": [\"machine learning\", \"deep learning\", \"artificial intelligence\", \"tensorflow\", \"pytorch\", \"keras\", \"scikit-learn\", \"sklearn\", \"nlp\", \"computer vision\", \"opencv\"],\n",
        "  \"cloud\": [\"aws\", \"azure\", \"gcp\", \"cloud\", \"ec2\", \"s3\", \"lambda\", \"kubernetes\", \"docker\", \"gke\", \"aks\", \"eks\"],\n",
        "  \"tools\": [\"git\", \"github\", \"gitlab\", \"jenkins\", \"jira\", \"confluence\", \"docker\", \"kubernetes\", \"terraform\", \"ansible\"],\n",
        "  \"methodologies\": [\"agile\", \"scrum\", \"devops\", \"ci/cd\", \"tdd\", \"waterfall\"],\n",
        "  \"data\": [\"data analysis\", \"data science\", \"data visualization\", \"tableau\", \"power bi\", \"excel\", \"pandas\", \"numpy\", \"scipy\", \"statsmodels\"],\n",
        "  \"soft_skills\": [\"leadership\", \"communication\", \"teamwork\", \"problem solving\", \"analytical\", \"critical thinking\"]\n",
        "}"
      ],
      "metadata": {
        "id": "j1Wvsb8P9ppR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CODE**"
      ],
      "metadata": {
        "id": "Ob9WvALu9rcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas nltk spacy scikit-learn matplotlib seaborn pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_olFNmNu40Wk",
        "outputId": "9af411f5-2788-43c4-b358-f52bc97e989d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-URxgZBU44GW",
        "outputId": "4ed6c09e-0d81-4eca-e7d8-6296aa445e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Advanced Resume Screening and Shortlisting System (Upgraded v2)\n",
        "Features: NLP, NER, TF-IDF, Cosine Similarity, Robust Experience/Name Extraction, Visualization\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import pdfplumber\n",
        "import logging\n",
        "import warnings # To handle the matplotlib warning\n",
        "\n",
        "# Suppress noisy logs from pdfminer (used by pdfplumber)\n",
        "logging.getLogger('pdfminer').setLevel(logging.ERROR)\n",
        "\n",
        "# --- NLTK Data Downloads ---\n",
        "def download_nltk_data():\n",
        "    \"\"\"Download required NLTK data models if not found.\"\"\"\n",
        "    nltk_packages = [\n",
        "        ('tokenizers/punkt', 'punkt'),\n",
        "        ('tokenizers/punkt_tab', 'punkt_tab'),\n",
        "        ('corpora/stopwords', 'stopwords'),\n",
        "        ('corpora/wordnet', 'wordnet'),\n",
        "        ('corpora/omw-1.4', 'omw-1.4')\n",
        "    ]\n",
        "    for path, package_id in nltk_packages:\n",
        "        try:\n",
        "            nltk.data.find(path)\n",
        "        except LookupError:\n",
        "            print(f\"Downloading NLTK package: {package_id}...\")\n",
        "            nltk.download(package_id)\n",
        "\n",
        "download_nltk_data()\n",
        "\n",
        "# --- Load spaCy model for NER ---\n",
        "def load_spacy_model(model_name=\"en_core_web_sm\"):\n",
        "    \"\"\"Load or download spaCy model.\"\"\"\n",
        "    try:\n",
        "        nlp = spacy.load(model_name)\n",
        "    except:\n",
        "        print(f\"Downloading spaCy model: {model_name}...\")\n",
        "        os.system(f\"python -m spacy download {model_name}\")\n",
        "        nlp = spacy.load(model_name)\n",
        "    return nlp\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "\n",
        "class AdvancedResumeScreener:\n",
        "    \"\"\"\n",
        "    Advanced Resume Screening System with NER, TF-IDF, Experience, Education, and Visualization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, skills_db_path='skills_db.json'):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english')) - {'and', 'to', 'of'}\n",
        "        self.nlp = nlp\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "\n",
        "        # --- NEW: Blacklist for common non-name headers ---\n",
        "        self.NAME_BLACKLIST = {\n",
        "            'linkedin', 'github', 'portfolio', 'profile', 'leetcode', 'email', 'phone',\n",
        "            'address', 'resume', 'cv', 'work', 'contact', 'experience', 'education',\n",
        "            'skills', 'projects', 'summary'\n",
        "        }\n",
        "\n",
        "        # Education degrees\n",
        "        self.education_keywords = {\n",
        "            'phd': ['phd', 'ph.d', 'doctorate', 'doctoral'],\n",
        "            'masters': ['masters', 'master', 'msc', 'm.sc', 'ma', 'm.a', 'mba', 'm.b.a', 'mtech', 'm.tech'],\n",
        "            'bachelors': ['bachelors', 'bachelor', 'bsc', 'b.sc', 'ba', 'b.a', 'btech', 'b.tech', 'be', 'b.e'],\n",
        "            'diploma': ['diploma', 'associate']\n",
        "        }\n",
        "\n",
        "        # Load skills from external JSON\n",
        "        self.technical_skills = self.load_skills_from_json(skills_db_path)\n",
        "\n",
        "        # Initialize TF-IDF Vectorizer\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2)  # Capture single words and two-word phrases\n",
        "        )\n",
        "\n",
        "    def load_skills_from_json(self, json_path):\n",
        "        \"\"\"Loads the skills database from an external JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                print(f\"Loading skills database from {json_path}...\")\n",
        "                return json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {json_path} not found. Using empty skills DB.\")\n",
        "            return {}\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error: Could not decode {json_path}. Using empty skills DB.\")\n",
        "            return {}\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract text from PDF resume using pdfplumber for better layout handling\"\"\"\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    # Extract text, respecting layout\n",
        "                    page_text = page.extract_text(x_tolerance=2, y_tolerance=2)\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {pdf_path} with pdfplumber: {str(e)}\")\n",
        "            return \"\"  # Return empty string on failure\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Preprocess text with cleaning, tokenization, and lemmatization\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\\\x[a-f0-9]{2}', '', text)  # Remove hex characters\n",
        "        text = re.sub(r'\\\\[abtnr]', '', text)     # Remove escape sequences\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)       # Remove punctuation\n",
        "        text = re.sub(r'\\s+', ' ', text)           # Condense whitespace\n",
        "\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 1]\n",
        "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    # ---\n",
        "    # --- THIS FUNCTION IS RECTIFIED ---\n",
        "    # ---\n",
        "    def extract_contact_info_and_name(self, text, doc):\n",
        "        \"\"\"\n",
        "        Extracts contact info using regex and a robust, multi-step name extraction logic\n",
        "        \"\"\"\n",
        "        info = {\n",
        "            'name': 'Unknown',\n",
        "            'email': 'N/A',\n",
        "            'phone': 'N/A'\n",
        "        }\n",
        "\n",
        "        # --- 1. Extract Name (More Robust Multi-Step Logic) ---\n",
        "\n",
        "        # Step 1: High-Confidence Search\n",
        "        # Look for a 'PERSON' entity in the first 75 tokens (the top of the resume)\n",
        "        person_entities = [ent.text for ent in doc[:75].ents if ent.label_ == 'PERSON']\n",
        "        if person_entities:\n",
        "            info['name'] = person_entities[0] # Take the first one\n",
        "\n",
        "        # Step 2: Blacklist Check\n",
        "        # Check if the found name is likely a header (e.g., \"LinkedIn\")\n",
        "        name_parts = set(info['name'].lower().split())\n",
        "        if info['name'] == 'Unknown' or name_parts.intersection(self.NAME_BLACKLIST):\n",
        "            # Name is \"Unknown\" OR it's a blacklisted word, so we reset and try Fallback 1\n",
        "            info['name'] = 'Unknown'\n",
        "\n",
        "            # Fallback 1: Try the Proper Noun (PROPN) Matcher\n",
        "            # This is what we had before, but now it's only a fallback\n",
        "            pattern1 = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "            pattern2 = [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "\n",
        "            if \"NAME_PATTERN_1\" not in self.matcher._patterns:\n",
        "                self.matcher.add(\"NAME_PATTERN_1\", [pattern1], on_match=None)\n",
        "            if \"NAME_PATTERN_2\" not in self.matcher._patterns:\n",
        "                self.matcher.add(\"NAME_PATTERN_2\", [pattern2], on_match=None)\n",
        "\n",
        "            matches = self.matcher(doc[:75])\n",
        "            if matches:\n",
        "                matches.sort(key=lambda x: x[2] - x[1], reverse=True) # Get longest match\n",
        "                match_id, start, end = matches[0]\n",
        "                potential_name = doc[start:end].text\n",
        "\n",
        "                # Check blacklist *again*\n",
        "                potential_name_parts = set(potential_name.lower().split())\n",
        "                if not potential_name_parts.intersection(self.NAME_BLACKLIST):\n",
        "                    info['name'] = potential_name\n",
        "\n",
        "        # Fallback 2: Last Resort\n",
        "        # If name is *still* Unknown, search the *entire document* for the first PERSON entity\n",
        "        if info['name'] == 'Unknown':\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == 'PERSON':\n",
        "                    name_parts = set(ent.text.lower().split())\n",
        "                    if not name_parts.intersection(self.NAME_BLACKLIST):\n",
        "                        info['name'] = ent.text\n",
        "                        break  # Take the first valid one\n",
        "\n",
        "        # --- 2. Extract Email ---\n",
        "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "        email_match = re.search(email_pattern, text)\n",
        "        if email_match:\n",
        "            info['email'] = email_match.group(0)\n",
        "\n",
        "        # --- 3. Extract Phone ---\n",
        "        # More comprehensive phone regex\n",
        "        phone_pattern = r'(\\(?\\+?\\d{1,3}\\)?[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?[\\d\\s-]{10,15}\\b'\n",
        "        phone_match = re.search(phone_pattern, text)\n",
        "        if phone_match:\n",
        "            info['phone'] = phone_match.group(0).strip()\n",
        "\n",
        "        return info\n",
        "\n",
        "    def extract_experience(self, text):\n",
        "        \"\"\"\n",
        "        Extract years of experience from resume by parsing date ranges.\n",
        "        \"\"\"\n",
        "        # Regex to find date ranges\n",
        "        date_range_pattern = re.compile(\n",
        "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\w.]{0,6}\\s+\\d{4}|'  # Month YYYY\n",
        "            r'\\d{1,2}[\\/.-]\\d{4}|'  # MM/YYYY\n",
        "            r'\\b\\d{4}\\b)'  # YYYY\n",
        "            r'\\s*(?:[-–—toTO])\\s*'\n",
        "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\w.]{0,6}\\s+\\d{4}|'  # Month YYYY\n",
        "            r'\\d{1,2}[\\/.-]\\d{4}|'  # MM/YYYY\n",
        "            r'\\b\\d{4}\\b|'  # YYYY\n",
        "            r'Present|Current|Till Date|Now)',  # Present\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        matches = date_range_pattern.findall(text)\n",
        "\n",
        "        if not matches:\n",
        "            # Fallback to simple \"X years experience\" if no date ranges found\n",
        "            exp_patterns = r'(\\d+)\\+?\\s*(?:years?|yrs?)\\s*(?:of)?\\s*experience'\n",
        "            exp_match = re.search(exp_patterns, text.lower())\n",
        "            if exp_match:\n",
        "                return {'total_years': int(exp_match.group(1))}\n",
        "            return {'total_years': 0}\n",
        "\n",
        "        month_map = {\n",
        "            'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
        "            'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "        }\n",
        "\n",
        "        def parse_date(date_str):\n",
        "            date_str = date_str.lower().strip().replace('.', '')\n",
        "\n",
        "            # Case 1: Present/Current\n",
        "            if date_str in ['present', 'current', 'till date', 'now']:\n",
        "                return datetime.now()\n",
        "\n",
        "            # Case 2: Month YYYY (e.g., \"Jan 2020\" or \"September 2020\")\n",
        "            for month_name, month_num in month_map.items():\n",
        "                if date_str.startswith(month_name):\n",
        "                    year_match = re.search(r'(\\d{4})', date_str)\n",
        "                    if year_match:\n",
        "                        return datetime(int(year_match.group(1)), month_num, 1)\n",
        "\n",
        "            # Case 3: MM/YYYY (e.g., \"01/2020\")\n",
        "            match = re.match(r'(\\d{1,2})[\\/.-](\\d{4})', date_str)\n",
        "            if match:\n",
        "                return datetime(int(match.group(2)), int(match.group(1)), 1)\n",
        "\n",
        "            # Case 4: YYYY (e.g., \"2020\")\n",
        "            match = re.match(r'^(\\d{4})$', date_str)\n",
        "            if match:\n",
        "                # Assume start of year if just YYYY\n",
        "                return datetime(int(match.group(1)), 1, 1)\n",
        "\n",
        "            return None # Could not parse\n",
        "\n",
        "        parsed_ranges = []\n",
        "        for start_str, end_str in matches:\n",
        "            start_date = parse_date(start_str)\n",
        "            end_date = parse_date(end_str)\n",
        "\n",
        "            if start_date and end_date:\n",
        "                parsed_ranges.append((start_date, end_date))\n",
        "\n",
        "        if not parsed_ranges:\n",
        "            return {'total_years': 0}\n",
        "\n",
        "        # --- Handle Overlaps ---\n",
        "        parsed_ranges.sort(key=lambda x: x[0])\n",
        "\n",
        "        merged_ranges = []\n",
        "        if parsed_ranges:\n",
        "            merged_ranges = [parsed_ranges[0]]\n",
        "            for current_start, current_end in parsed_ranges[1:]:\n",
        "                last_start, last_end = merged_ranges[-1]\n",
        "\n",
        "                if current_start <= last_end:\n",
        "                    new_end = max(last_end, current_end)\n",
        "                    merged_ranges[-1] = (last_start, new_end)\n",
        "                else:\n",
        "                    merged_ranges.append((current_start, current_end))\n",
        "\n",
        "        # Calculate total duration from merged, non-overlapping ranges\n",
        "        total_months = 0\n",
        "        for start_date, end_date in merged_ranges:\n",
        "            months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
        "            total_months += (months + 1) # Add 1 for inclusivity\n",
        "\n",
        "        return {'total_years': round(total_months / 12, 1)}\n",
        "\n",
        "    def extract_education(self, text, doc):\n",
        "        \"\"\"\n",
        "        Extract education qualifications from resume\n",
        "        Returns: Dictionary with education details\n",
        "        \"\"\"\n",
        "        education_info = {\n",
        "            'highest_degree': 'None',\n",
        "            'degrees': [],\n",
        "            'institutions': []\n",
        "        }\n",
        "        text_lower = text.lower()\n",
        "        degree_priority = ['phd', 'masters', 'bachelors', 'diploma']\n",
        "\n",
        "        for degree in degree_priority:\n",
        "            for keyword in self.education_keywords[degree]:\n",
        "                if keyword in text_lower:\n",
        "                    if education_info['highest_degree'] == 'None':\n",
        "                        education_info['highest_degree'] = degree.title()\n",
        "                    if degree.title() not in education_info['degrees']:\n",
        "                        education_info['degrees'].append(degree.title())\n",
        "\n",
        "        # Extract university/college names using NER\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'ORG':\n",
        "                org_lower = ent.text.lower()\n",
        "                if any(word in org_lower for word in ['university', 'college', 'institute', 'school']):\n",
        "                    if ent.text not in education_info['institutions']:\n",
        "                        education_info['institutions'].append(ent.text)\n",
        "\n",
        "        education_info['institutions'] = list(set(education_info['institutions']))\n",
        "        return education_info\n",
        "\n",
        "    def extract_skills(self, text, custom_skills=None):\n",
        "        \"\"\"\n",
        "        Extract skills from text with categorization\n",
        "        Returns: Dictionary with categorized skills\n",
        "        \"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_skills = {\n",
        "            'all_skills': [],\n",
        "            'by_category': {}\n",
        "        }\n",
        "\n",
        "        # Use custom skills if provided, otherwise use default\n",
        "        skills_db = custom_skills if custom_skills else self.technical_skills\n",
        "\n",
        "        for category, skills in skills_db.items():\n",
        "            found_in_category = []\n",
        "            for skill in skills:\n",
        "                # Use regex to match whole words to avoid partial matches (e.g., 'go' in 'golang')\n",
        "                # But for multi-word skills, just check for presence\n",
        "                if ' ' in skill:\n",
        "                    if skill.lower() in text_lower:\n",
        "                        found_in_category.append(skill)\n",
        "                else:\n",
        "                    if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text_lower):\n",
        "                        found_in_category.append(skill)\n",
        "\n",
        "            # Add to main lists\n",
        "            for skill in found_in_category:\n",
        "                if skill not in found_skills['all_skills']:\n",
        "                    found_skills['all_skills'].append(skill)\n",
        "\n",
        "            if found_in_category:\n",
        "                found_skills['by_category'][category] = list(set(found_in_category))\n",
        "\n",
        "        found_skills['all_skills'] = list(set(found_skills['all_skills']))\n",
        "        return found_skills\n",
        "\n",
        "    def calculate_jaccard_similarity(self, set1, set2):\n",
        "        \"\"\"Calculate Jaccard Similarity: J(A,B) = |A ∩ B| / |A ∪ B|\"\"\"\n",
        "        set1 = set([s.lower() for s in set1])\n",
        "        set2 = set([s.lower() for s in set2])\n",
        "\n",
        "        intersection = len(set1.intersection(set2))\n",
        "        union = len(set1.union(set2))\n",
        "\n",
        "        return intersection / union if union > 0 else 0.0\n",
        "\n",
        "    def calculate_composite_score(self, jd_info, resume_info, cosine_score, weights=None):\n",
        "        \"\"\"\n",
        "        Calculate composite score based on multiple factors, now including cosine similarity\n",
        "        \"\"\"\n",
        "        if weights is None:\n",
        "            # Added 'cosine' and re-balanced defaults\n",
        "            weights = {\n",
        "                'skills': 0.4,\n",
        "                'cosine': 0.3,\n",
        "                'experience': 0.2,\n",
        "                'education': 0.1\n",
        "            }\n",
        "\n",
        "        # 1. Skills score (Jaccard similarity)\n",
        "        skills_score = self.calculate_jaccard_similarity(\n",
        "            jd_info['skills']['all_skills'],\n",
        "            resume_info['skills']['all_skills']\n",
        "        )\n",
        "\n",
        "        # 2. Experience score\n",
        "        exp_score = 0\n",
        "        if 'required_experience' in jd_info and jd_info['required_experience'] > 0:\n",
        "            # Cap at 1.0 (meeting requirement is 100%)\n",
        "            exp_ratio = min(resume_info['experience']['total_years'] / jd_info['required_experience'], 1.0)\n",
        "            exp_score = exp_ratio\n",
        "        else:\n",
        "            # If JD doesn't specify, score based on a 5-year benchmark\n",
        "            exp_score = min(resume_info['experience']['total_years'] / 5.0, 1.0)\n",
        "\n",
        "        # 3. Education score\n",
        "        edu_score = 0\n",
        "        degree_hierarchy = {'None': 0, 'Diploma': 1, 'Bachelors': 2, 'Masters': 3, 'Phd': 4}\n",
        "\n",
        "        if 'required_education' in jd_info and jd_info['required_education'] != 'None':\n",
        "            required_level = degree_hierarchy.get(jd_info['required_education'], 0)\n",
        "            candidate_level = degree_hierarchy.get(resume_info['education']['highest_degree'], 0)\n",
        "\n",
        "            if candidate_level >= required_level:\n",
        "                edu_score = 1.0 # Meets or exceeds requirement\n",
        "            elif required_level > 0:\n",
        "                edu_score = candidate_level / required_level # Prorated score\n",
        "            else:\n",
        "                edu_score = 0.5 # No requirement specified, neutral score\n",
        "        else:\n",
        "            # If JD doesn't specify, score based on a Master's (3) benchmark\n",
        "            edu_score = min(degree_hierarchy.get(resume_info['education']['highest_degree'], 0) / 3.0, 1.0)\n",
        "\n",
        "        # 4. Cosine Score (already 0-1)\n",
        "        # We use the passed-in cosine_score directly\n",
        "\n",
        "        # Calculate weighted composite score\n",
        "        composite_score = (\n",
        "            weights['skills'] * skills_score +\n",
        "            weights['cosine'] * cosine_score +\n",
        "            weights['experience'] * exp_score +\n",
        "            weights['education'] * edu_score\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'composite_score': composite_score,\n",
        "            'skills_score': skills_score,\n",
        "            'cosine_score': cosine_score,\n",
        "            'experience_score': exp_score,\n",
        "            'education_score': edu_score\n",
        "        }\n",
        "\n",
        "    def parse_job_description(self, jd_text):\n",
        "        \"\"\"Parse job description to extract requirements\"\"\"\n",
        "        doc = self.nlp(jd_text)\n",
        "\n",
        "        jd_info = {\n",
        "            'text': jd_text,\n",
        "            'processed_text': self.preprocess_text(jd_text),\n",
        "            'skills': self.extract_skills(jd_text),\n",
        "            'experience': self.extract_experience(jd_text),\n",
        "            'education': self.extract_education(jd_text, doc),\n",
        "            'contact_info': self.extract_contact_info_and_name(jd_text, doc) # Use new function\n",
        "        }\n",
        "\n",
        "        jd_info['required_experience'] = jd_info['experience']['total_years']\n",
        "        jd_info['required_education'] = jd_info['education']['highest_degree']\n",
        "\n",
        "        return jd_info\n",
        "\n",
        "    def screen_resumes(self, job_description, resume_folder, top_n=5, weights=None):\n",
        "        \"\"\"\n",
        "        Screen resumes with advanced analysis\n",
        "        \"\"\"\n",
        "        # Parse job description\n",
        "        print(\"Parsing Job Description...\")\n",
        "        jd_info = self.parse_job_description(job_description)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"JOB DESCRIPTION ANALYSIS\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Required Skills: {len(jd_info['skills']['all_skills'])}\")\n",
        "        print(f\"Skills: {', '.join(jd_info['skills']['all_skills'][:10])}...\")\n",
        "        print(f\"Required Experience: {jd_info['required_experience']} years\")\n",
        "        print(f\"Required Education: {jd_info['required_education']}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        # Process all resumes\n",
        "        results = []\n",
        "        pdf_files = [f for f in os.listdir(resume_folder) if f.endswith('.pdf')]\n",
        "\n",
        "        if not pdf_files:\n",
        "            print(\"No PDF files found in the folder!\")\n",
        "            return pd.DataFrame(), jd_info, pd.DataFrame()\n",
        "\n",
        "        print(f\"Processing {len(pdf_files)} resumes...\\n\")\n",
        "\n",
        "        # --- Prepare for Cosine Similarity ---\n",
        "        resume_texts = []\n",
        "        valid_pdf_files = [] # Keep track of files that were successfully read\n",
        "        for pdf_file in pdf_files:\n",
        "            pdf_path = os.path.join(resume_folder, pdf_file)\n",
        "            resume_text = self.extract_text_from_pdf(pdf_path)\n",
        "            if resume_text:\n",
        "                resume_texts.append(resume_text)\n",
        "                valid_pdf_files.append(pdf_file)\n",
        "            else:\n",
        "                 print(f\"Skipping {pdf_file}: Could not extract text.\")\n",
        "\n",
        "        if not resume_texts:\n",
        "            print(\"No resumes could be read.\")\n",
        "            return pd.DataFrame(), jd_info, pd.DataFrame()\n",
        "\n",
        "        # Preprocess all texts\n",
        "        jd_processed = jd_info['processed_text']\n",
        "        resumes_processed = [self.preprocess_text(t) for t in resume_texts]\n",
        "\n",
        "        # Fit and Transform with TF-IDF\n",
        "        corpus = [jd_processed] + resumes_processed\n",
        "        self.tfidf_vectorizer.fit(corpus)\n",
        "\n",
        "        jd_vector = self.tfidf_vectorizer.transform([jd_processed])\n",
        "        resumes_vector = self.tfidf_vectorizer.transform(resumes_processed)\n",
        "\n",
        "        # Calculate Cosine Similarity for all resumes at once\n",
        "        cosine_scores = cosine_similarity(jd_vector, resumes_vector)[0]\n",
        "\n",
        "        # --- Loop and analyze each resume ---\n",
        "        for idx, pdf_file in enumerate(valid_pdf_files):\n",
        "            print(f\"Analyzing {idx+1}/{len(valid_pdf_files)}: {pdf_file}\")\n",
        "\n",
        "            resume_text = resume_texts[idx]\n",
        "            resume_processed = resumes_processed[idx]\n",
        "\n",
        "            doc = self.nlp(resume_text)\n",
        "\n",
        "            # Analyze resume\n",
        "            resume_info = {\n",
        "                'text': resume_text,\n",
        "                'processed_text': resume_processed,\n",
        "                'contact_info': self.extract_contact_info_and_name(resume_text, doc),\n",
        "                'skills': self.extract_skills(resume_text),\n",
        "                'experience': self.extract_experience(resume_text),\n",
        "                'education': self.extract_education(resume_text, doc)\n",
        "            }\n",
        "\n",
        "            cosine_score = cosine_scores[idx]\n",
        "            scores = self.calculate_composite_score(jd_info, resume_info, cosine_score, weights)\n",
        "\n",
        "            matched_skills = list(set([s.lower() for s in jd_info['skills']['all_skills']]).intersection(\n",
        "                set([s.lower() for s in resume_info['skills']['all_skills']])\n",
        "            ))\n",
        "\n",
        "            results.append({\n",
        "                'Resume': pdf_file,\n",
        "                'Candidate_Name': resume_info['contact_info']['name'],\n",
        "                'Composite_Score': scores['composite_score'],\n",
        "                'Cosine_Score': scores['cosine_score'],\n",
        "                'Skills_Score': scores['skills_score'],\n",
        "                'Experience_Score': scores['experience_score'],\n",
        "                'Education_Score': scores['education_score'],\n",
        "                'Total_Years_Experience': resume_info['experience']['total_years'],\n",
        "                'Highest_Degree': resume_info['education']['highest_degree'],\n",
        "                'Matched_Skills': len(matched_skills),\n",
        "                'Total_JD_Skills': len(jd_info['skills']['all_skills']),\n",
        "                'Total_Resume_Skills': len(resume_info['skills']['all_skills']),\n",
        "                'Skills_List': ', '.join(matched_skills),\n",
        "                'Match_Percentage': (len(matched_skills) / len(jd_info['skills']['all_skills']) * 100) if len(jd_info['skills']['all_skills']) > 0 else 0,\n",
        "                'Email': resume_info['contact_info']['email'],\n",
        "                'Phone': resume_info['contact_info']['phone'],\n",
        "                'Skills_By_Category': json.dumps(resume_info['skills']['by_category'])\n",
        "            })\n",
        "\n",
        "        # Create DataFrame and sort\n",
        "        df_results = pd.DataFrame(results)\n",
        "        df_results = df_results.sort_values('Composite_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        return df_results.head(top_n), jd_info, df_results # Return all results for visualization\n",
        "\n",
        "    def visualize_results(self, all_results_df, jd_info, output_folder='visualizations'):\n",
        "        \"\"\"\n",
        "        Create comprehensive visualizations of screening results\n",
        "        \"\"\"\n",
        "        if all_results_df.empty:\n",
        "            print(\"No results to visualize!\")\n",
        "            return\n",
        "\n",
        "        # Use top 15 for visualization to keep charts readable\n",
        "        results_df = all_results_df.head(15)\n",
        "\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "        # 1. Composite Score Comparison (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, max(8, len(results_df) * 0.5)))\n",
        "        candidates = [f\"{row['Candidate_Name']}\\n({row['Resume']})\" for _, row in results_df.iterrows()]\n",
        "        scores = results_df['Composite_Score'].values\n",
        "\n",
        "        colors = sns.color_palette(\"RdYlGn\", len(candidates))\n",
        "        bars = ax.barh(candidates, scores, color=colors)\n",
        "        ax.set_xlabel('Composite Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title(f'Top {len(results_df)} Candidates - Composite Score Ranking', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.set_xlim(0, 1)\n",
        "        ax.invert_yaxis() # Show rank #1 at the top\n",
        "\n",
        "        for i, (bar, score) in enumerate(zip(bars, scores)):\n",
        "            ax.text(score + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                   f'{score:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/1_composite_scores.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/1_composite_scores.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 2. Multi-dimensional Score Breakdown (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "        # Melt the dataframe for easier plotting with seaborn\n",
        "        df_melted = results_df.melt(\n",
        "            id_vars='Candidate_Name',\n",
        "            value_vars=['Skills_Score', 'Cosine_Score', 'Experience_Score', 'Education_Score'],\n",
        "            var_name='Score_Type',\n",
        "            value_name='Score'\n",
        "        )\n",
        "\n",
        "        sns.barplot(x='Candidate_Name', y='Score', hue='Score_Type', data=df_melted, ax=ax, palette='Set2')\n",
        "        ax.set_xlabel('Candidates', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Score Breakdown by Dimension', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "        # --- THIS IS THE FIX for the UserWarning ---\n",
        "        # We set the rotation on the tick parameters\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "        # Manually adjust layout to prevent labels from being cut off\n",
        "        plt.setp(ax.get_xticklabels(), ha='right')\n",
        "\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.set_ylim(0, 1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/2_score_breakdown.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/2_score_breakdown.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 3. Skills Match Visualization (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, max(8, len(results_df) * 0.5)))\n",
        "        candidates_short = [row['Candidate_Name'] for _, row in results_df.iterrows()]\n",
        "        matched = results_df['Matched_Skills'].values\n",
        "        total_jd = results_df['Total_JD_Skills'].values[0] if len(results_df) > 0 else 0\n",
        "        unmatched = [total_jd - m for m in matched]\n",
        "\n",
        "        bars1 = ax.barh(candidates_short, matched, label='Matched Skills', color='#27ae60')\n",
        "        bars2 = ax.barh(candidates_short, unmatched, left=matched, label='Unmatched Skills (JD)', color='#ecf0f1')\n",
        "        ax.set_xlabel('Number of Skills', fontsize=12, fontweight='bold')\n",
        "        ax.set_title(f'Skills Match Analysis (Total Required: {total_jd})', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.invert_yaxis()\n",
        "\n",
        "        for i, (m, u) in enumerate(zip(matched, unmatched)):\n",
        "            percentage = (m / total_jd * 100) if total_jd > 0 else 0\n",
        "            ax.text(m/2, i, f'{m}', ha='center', va='center', fontweight='bold', color='white')\n",
        "            ax.text(m + u + 0.5, i, f'{percentage:.1f}%', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/3_skills_match.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/3_skills_match.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 4. Experience vs Score Scatter (All Candidates)\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        scatter = ax.scatter(all_results_df['Total_Years_Experience'],\n",
        "                             all_results_df['Composite_Score'],\n",
        "                             s=100, alpha=0.6, c=all_results_df['Composite_Score'],\n",
        "                             cmap='viridis', edgecolors='black', linewidth=1)\n",
        "\n",
        "        # Annotate top 5\n",
        "        for idx, row in all_results_df.head(5).iterrows():\n",
        "            ax.annotate(row['Candidate_Name'],\n",
        "                       (row['Total_Years_Experience'], row['Composite_Score']),\n",
        "                       xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # Add JD requirement line\n",
        "        if jd_info['required_experience'] > 0:\n",
        "            ax.axvline(x=jd_info['required_experience'], color='red', linestyle='--', label=f'JD Req: {jd_info[\"required_experience\"]} yrs')\n",
        "            ax.legend()\n",
        "\n",
        "        ax.set_xlabel('Years of Experience', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Composite Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Experience vs Composite Score (All Candidates)', fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.colorbar(scatter, ax=ax, label='Composite Score')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/4_experience_vs_score.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/4_experience_vs_score.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 5. Education Distribution (All Candidates)\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        edu_counts = all_results_df['Highest_Degree'].value_counts()\n",
        "        colors_pie = sns.color_palette(\"Set2\", len(edu_counts))\n",
        "\n",
        "        wedges, texts, autotexts = ax.pie(edu_counts.values, labels=edu_counts.index,\n",
        "                                          autopct='%1.1f%%', startangle=90,\n",
        "                                          colors=colors_pie, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
        "        ax.set_title('Education Level Distribution (All Candidates)', fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/5_education_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/5_education_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 6. Radar Chart for Top 3 Candidates\n",
        "        if len(results_df) >= 3:\n",
        "            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "            categories = ['Skills', 'Semantic Match', 'Experience', 'Education']\n",
        "            num_vars = len(categories)\n",
        "\n",
        "            angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "            angles += angles[:1]\n",
        "\n",
        "            ax.set_theta_offset(np.pi / 2)\n",
        "            ax.set_theta_direction(-1)\n",
        "            ax.set_xticks(angles[:-1])\n",
        "            ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n",
        "\n",
        "            colors_radar = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "\n",
        "            for idx in range(min(3, len(results_df))):\n",
        "                row = results_df.iloc[idx]\n",
        "                values = [row['Skills_Score'], row['Cosine_Score'], row['Experience_Score'], row['Education_Score']]\n",
        "                values += values[:1]\n",
        "\n",
        "                ax.plot(angles, values, 'o-', linewidth=2, label=row['Candidate_Name'], color=colors_radar[idx])\n",
        "                ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])\n",
        "\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.set_title('Top 3 Candidates - Profile Radar', fontsize=14, fontweight='bold', pad=30)\n",
        "            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{output_folder}/6_radar_chart.png', dpi=300, bbox_inches='tight')\n",
        "            print(f\"✓ Saved: {output_folder}/6_radar_chart.png\")\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\n✓ All visualizations saved in '{output_folder}' folder!\")\n",
        "\n",
        "    def display_results(self, results_df, jd_info):\n",
        "        \"\"\"Display detailed screening results\"\"\"\n",
        "        if results_df.empty:\n",
        "            print(\"No results to display!\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"{'TOP ' + str(len(results_df)) + ' SHORTLISTED CANDIDATES':^100}\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        for idx, row in results_df.iterrows():\n",
        "            rank = idx + 1\n",
        "            print(f\"\\n{'RANK #' + str(rank):^100}\")\n",
        "            print(\"-\" * 100)\n",
        "            print(f\"{'Candidate:':<25} {row['Candidate_Name']}\")\n",
        "            print(f\"{'Resume File:':<25} {row['Resume']}\")\n",
        "            print(f\"{'Email:':<25} {row['Email']}\")\n",
        "            print(f\"{'Phone:':<25} {row['Phone']}\")\n",
        "            print()\n",
        "            print(f\"{'SCORES:':<25}\")\n",
        "            print(f\"{'  Composite Score:':<25} {row['Composite_Score']:.4f} ({row['Composite_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Skills (Jaccard) Score:':<25} {row['Skills_Score']:.4f} ({row['Skills_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Semantic (Cosine) Score:':<25} {row['Cosine_Score']:.4f} ({row['Cosine_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Experience Score:':<25} {row['Experience_Score']:.4f} ({row['Experience_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Education Score:':<25} {row['Education_Score']:.4f} ({row['Education_Score']*100:.1f}%)\")\n",
        "            print()\n",
        "            print(f\"{'QUALIFICATIONS:':<25}\")\n",
        "            print(f\"{'  Experience:':<25} {row['Total_Years_Experience']} years (JD: {jd_info['required_experience']} yrs)\")\n",
        "            print(f\"{'  Education:':<25} {row['Highest_Degree']} (JD: {jd_info['required_education']})\")\n",
        "            print(f\"{'  Matched Skills:':<25} {row['Matched_Skills']} of {row['Total_JD_Skills']} ({row['Match_Percentage']:.1f}%)\")\n",
        "            print(f\"{'  Total Skills:':<25} {row['Total_Resume_Skills']}\")\n",
        "            print()\n",
        "            print(f\"{'MATCHED SKILLS:':<25}\")\n",
        "            skills_list = row['Skills_List'].split(', ') if row['Skills_List'] else [\"None\"]\n",
        "            for i in range(0, len(skills_list), 5):\n",
        "                print(f\"{'  ':<25} {', '.join(skills_list[i:i+5])}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
        "\n",
        "    def save_results(self, results_df, output_file='screening_results.csv'):\n",
        "        \"\"\"Save detailed results to CSV\"\"\"\n",
        "        results_df.to_csv(output_file, index=False)\n",
        "        print(f\"✓ Results saved to {output_file}\")\n",
        "\n",
        "    def generate_report(self, results_df, jd_info, all_results_df, output_file='screening_report.html'):\n",
        "        \"\"\"Generate HTML report with all results\"\"\"\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Resume Screening Report</title>\n",
        "            <style>\n",
        "                body {{\n",
        "                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "                    margin: 40px;\n",
        "                    background-color: #f5f5f5;\n",
        "                }}\n",
        "                .header {{\n",
        "                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    color: white;\n",
        "                    padding: 30px;\n",
        "                    border-radius: 10px;\n",
        "                    margin-bottom: 30px;\n",
        "                    box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "                }}\n",
        "                .header h1 {{ margin: 0; font-size: 32px; }}\n",
        "                .jd-section {{\n",
        "                    background: white;\n",
        "                    padding: 25px;\n",
        "                    border-radius: 10px;\n",
        "                    margin-bottom: 30px;\n",
        "                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "                }}\n",
        "                .candidate {{\n",
        "                    background: white;\n",
        "                    padding: 25px;\n",
        "                    margin-bottom: 20px;\n",
        "                    border-radius: 10px;\n",
        "                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "                    border-left: 5px solid #667eea;\n",
        "                }}\n",
        "                .rank {{\n",
        "                    display: inline-block;\n",
        "                    background: #667eea;\n",
        "                    color: white;\n",
        "                    padding: 8px 15px;\n",
        "                    border-radius: 20px;\n",
        "                    font-weight: bold;\n",
        "                    font-size: 18px;\n",
        "                }}\n",
        "                .score-container {{\n",
        "                    display: grid;\n",
        "                    grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));\n",
        "                    gap: 15px;\n",
        "                    margin: 20px 0;\n",
        "                }}\n",
        "                .score-box {{\n",
        "                    background: #f8f9fa;\n",
        "                    padding: 15px;\n",
        "                    border-radius: 8px;\n",
        "                    text-align: center;\n",
        "                    border-bottom: 3px solid #667eea;\n",
        "                }}\n",
        "                .score-value {{\n",
        "                    font-size: 28px;\n",
        "                    font-weight: bold;\n",
        "                    color: #667eea;\n",
        "                }}\n",
        "                .score-label {{ color: #666; font-size: 14px; margin-top: 5px; }}\n",
        "                .skills {{ display: flex; flex-wrap: wrap; gap: 8px; margin-top: 15px; }}\n",
        "                .skill-tag {{\n",
        "                    background: #e3f2fd;\n",
        "                    color: #1976d2;\n",
        "                    padding: 5px 12px;\n",
        "                    border-radius: 15px;\n",
        "                    font-size: 13px;\n",
        "                }}\n",
        "                .info-row {{\n",
        "                    display: flex;\n",
        "                    justify-content: space-between;\n",
        "                    padding: 10px 0;\n",
        "                    border-bottom: 1px solid #eee;\n",
        "                }}\n",
        "                .info-label {{ font-weight: bold; color: #555; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"header\">\n",
        "                <h1>📋 Resume Screening Report</h1>\n",
        "                <p>Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"jd-section\">\n",
        "                <h2>📄 Job Description Analysis</h2>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">Total Required Skills:</span>\n",
        "                    <span>{len(jd_info['skills']['all_skills'])}</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">Required Experience:</span>\n",
        "                    <span>{jd_info['required_experience']} years</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">Required Education:</span>\n",
        "                    <span>{jd_info['required_education']}</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">Total Candidates Screened:</span>\n",
        "                    <span>{len(all_results_df)}</span>\n",
        "                </div>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "\n",
        "        for idx, row in results_df.iterrows():\n",
        "            rank = idx + 1\n",
        "            skills_list = row['Skills_List'].split(', ') if row['Skills_List'] else []\n",
        "            skills_html = ''.join([f'<span class=\"skill-tag\">{skill}</span>' for skill in skills_list])\n",
        "            if not skills_html: skills_html = \"<span>No matched skills found.</span>\"\n",
        "\n",
        "            html_content += f\"\"\"\n",
        "            <div class=\"candidate\">\n",
        "                <span class=\"rank\">Rank #{rank}</span>\n",
        "                <h2 style=\"margin-top: 15px;\">{row['Candidate_Name']}</h2>\n",
        "                <p style=\"color: #666;\">{row['Resume']}</p>\n",
        "\n",
        "                <div class=\"score-container\">\n",
        "                    <div class=\"score-box\">\n",
        "                        <div class=\"score-value\">{row['Composite_Score']:.3f}</div>\n",
        "                        <div class=\"score-label\">Composite</div>\n",
        "                    </div>\n",
        "                    <div class=\"score-box\">\n",
        "                        <div class=\"score-value\">{row['Skills_Score']:.3f}</div>\n",
        "                        <div class=\"score-label\">Skills (Jaccard)</div>\n",
        "                    </div>\n",
        "                    <div class=\"score-box\">\n",
        "                        <div class=\"score-value\">{row['Cosine_Score']:.3f}</div>\n",
        "                        <div class=\"score-label\">Semantic (Cosine)</div>\n",
        "                    </div>\n",
        "                    <div class=\"score-box\">\n",
        "                        <div class=\"score-value\">{row['Experience_Score']:.3f}</div>\n",
        "                        <div class=\"score-label\">Experience</div>\n",
        "                    </div>\n",
        "                    <div class=\"score-box\">\n",
        "                        <div class=\"score-value\">{row['Education_Score']:.3f}</div>\n",
        "                        <div class=\"score-label\">Education</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">📧 Email:</span>\n",
        "                    <span>{row['Email']}</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">📱 Phone:</span>\n",
        "                    <span>{row['Phone']}</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">💼 Experience:</span>\n",
        "                    <span>{row['Total_Years_Experience']} years</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">🎓 Education:</span>\n",
        "                    <span>{row['Highest_Degree']}</span>\n",
        "                </div>\n",
        "                <div class=\"info-row\">\n",
        "                    <span class=\"info-label\">✅ Skills Match:</span>\n",
        "                    <span>{row['Matched_Skills']} of {row['Total_JD_Skills']} ({row['Match_Percentage']:.1f}%)</span>\n",
        "                </div>\n",
        "\n",
        "                <h3 style=\"margin-top: 20px;\">Matched Skills:</h3>\n",
        "                <div class=\"skills\">\n",
        "                    {skills_html}\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        print(f\"✓ HTML report saved to {output_file}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the advanced resume screening system\"\"\"\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'ADVANCED RESUME SCREENING SYSTEM':^100}\")\n",
        "    print(f\"{'with TF-IDF, NER, Experience Extraction & Visualization':^100}\")\n",
        "    print(\"=\"*100)\n",
        "    print()\n",
        "\n",
        "    # Initialize screener\n",
        "    # --- Make sure to use the correct path for your Colab environment ---\n",
        "    screener = AdvancedResumeScreener(skills_db_path='/content/drive/MyDrive/CDS_PROJECT/skills_db.json')\n",
        "\n",
        "    # Example job description\n",
        "    default_jd = \"\"\"\n",
        "    Senior Software Engineer - Machine Learning\n",
        "\n",
        "    We are seeking a talented Senior Software Engineer with 5+ years of experience to join our AI team.\n",
        "\n",
        "    Required Skills:\n",
        "    - Strong programming skills in Python and Java\n",
        "    - Experience with Machine Learning frameworks (TensorFlow, PyTorch, scikit-learn)\n",
        "    - Deep Learning and Neural Networks\n",
        "    - SQL and Database management (MySQL, PostgreSQL)\n",
        "    - REST API development and microservices architecture\n",
        "    - Cloud platforms (AWS, Azure, or GCP)\n",
        "    - Git version control and CI/CD pipelines\n",
        "    - Docker and Kubernetes\n",
        "\n",
        "    Required Qualifications:\n",
        "    - Bachelor's degree in Computer Science or related field (Master's preferred)\n",
        "    - 5+ years of professional software development experience\n",
        "    - Strong problem-solving and analytical skills\n",
        "    - Excellent communication and teamwork abilities\n",
        "\n",
        "    Preferred:\n",
        "    - Experience with NLP and Computer Vision\n",
        "    - Knowledge of Agile/Scrum methodologies\n",
        "    - Contributions to open-source projects\n",
        "    \"\"\"\n",
        "\n",
        "    # Get inputs\n",
        "    print(\"=\" * 100)\n",
        "    print(\"STEP 1: JOB DESCRIPTION\")\n",
        "    print(\"=\" * 100)\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. Use default job description (Senior Software Engineer - ML)\")\n",
        "    print(\"2. Enter custom job description\")\n",
        "    print(\"3. Load from file\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1/2/3) [default: 1]: \").strip()\n",
        "\n",
        "    if choice == '2':\n",
        "        print(\"\\nEnter job description (press Ctrl+D on Linux/macOS or Ctrl+Z+Enter on Windows when done):\")\n",
        "        job_description = \"\"\n",
        "        try:\n",
        "            while True:\n",
        "                line = input()\n",
        "                job_description += line + \"\\n\"\n",
        "        except EOFError:\n",
        "            pass\n",
        "    elif choice == '3':\n",
        "        jd_file = input(\"Enter path to job description file: \").strip()\n",
        "        try:\n",
        "            with open(jd_file, 'r', encoding='utf-8') as f:\n",
        "                job_description = f.read()\n",
        "        except:\n",
        "            print(\"Error reading file. Using default JD.\")\n",
        "            job_description = default_jd\n",
        "    else:\n",
        "        job_description = default_jd\n",
        "\n",
        "    # Get resume folder\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 2: RESUME FOLDER\")\n",
        "    print(\"=\" * 100)\n",
        "    resume_folder = input(\"\\nEnter path to resume folder [default: ./resumes]: \").strip()\n",
        "    if not resume_folder:\n",
        "        resume_folder = \"./resumes\"\n",
        "\n",
        "    if not os.path.exists(resume_folder):\n",
        "        print(f\"\\nFolder '{resume_folder}' not found!\")\n",
        "        create = input(\"Create folder? (y/n): \").strip().lower()\n",
        "        if create == 'y':\n",
        "            os.makedirs(resume_folder)\n",
        "            print(f\"✓ Folder created. Please add PDF resumes and run again.\")\n",
        "            return\n",
        "        else:\n",
        "            return\n",
        "\n",
        "    # Get top N\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 3: SCREENING PARAMETERS\")\n",
        "    print(\"=\" * 100)\n",
        "    top_n_input = input(\"\\nEnter number of top candidates to shortlist [default: 5]: \").strip()\n",
        "    top_n = int(top_n_input) if top_n_input.isdigit() and int(top_n_input) > 0 else 5\n",
        "\n",
        "    # Get scoring weights\n",
        "    print(\"\\nUse custom scoring weights? (y/n) [default: n]: \", end='')\n",
        "    custom_weights = input().strip().lower()\n",
        "\n",
        "    weights = None\n",
        "    if custom_weights == 'y':\n",
        "        print(\"\\nEnter weights (must sum to 1.0):\")\n",
        "        try:\n",
        "            skills_w = float(input(\"  Skills (Jaccard) weight [default: 0.4]: \") or 0.4)\n",
        "            cosine_w = float(input(\"  Semantic (Cosine) weight [default: 0.3]: \") or 0.3)\n",
        "            exp_w = float(input(\"  Experience weight [default: 0.2]: \") or 0.2)\n",
        "            edu_w = float(input(\"  Education weight [default: 0.1]: \") or 0.1)\n",
        "\n",
        "            if abs(skills_w + cosine_w + exp_w + edu_w - 1.0) < 0.01:\n",
        "                weights = {'skills': skills_w, 'cosine': cosine_w, 'experience': exp_w, 'education': edu_w}\n",
        "            else:\n",
        "                print(\"Weights don't sum to 1.0. Using defaults.\")\n",
        "        except:\n",
        "            print(\"Invalid input. Using default weights.\")\n",
        "\n",
        "    # Process resumes\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"PROCESSING RESUMES...\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    # Suppress warnings during visualization\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\", UserWarning)\n",
        "        top_results, jd_info, all_results = screener.screen_resumes(job_description, resume_folder, top_n, weights)\n",
        "\n",
        "    if top_results.empty:\n",
        "        print(\"\\n❌ No resumes could be processed!\")\n",
        "        return\n",
        "\n",
        "    # Display results\n",
        "    screener.display_results(top_results, jd_info)\n",
        "\n",
        "    # Save results\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"SAVING RESULTS...\")\n",
        "    print(\"=\" * 100)\n",
        "    screener.save_results(all_results, 'screening_results.csv') # Save all results\n",
        "\n",
        "    # Generate HTML report\n",
        "    screener.generate_report(top_results, jd_info, all_results, 'screening_report.html')\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"GENERATING VISUALIZATIONS...\")\n",
        "    print(\"=\" * 100)\n",
        "    visualize = input(\"\\nGenerate visualizations? (y/n) [default: y]: \").strip().lower()\n",
        "\n",
        "    if visualize != 'n':\n",
        "        # Suppress warnings during visualization\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\", UserWarning)\n",
        "            screener.visualize_results(all_results, jd_info, 'visualizations')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\"{'✓ SCREENING COMPLETED SUCCESSFULLY!':^100}\")\n",
        "    print(\"=\"*100)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(\"  📊 screening_results.csv - Detailed results for ALL candidates\")\n",
        "    print(\"  📄 screening_report.html - Interactive report of TOP candidates\")\n",
        "    if visualize != 'n':\n",
        "        print(\"  📈 visualizations/ - Folder containing all charts and graphs\")\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ2Pqs5820dw",
        "outputId": "f12e5e9e-752d-4672-f505-a6f2c26baed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK package: wordnet...\n",
            "Downloading NLTK package: omw-1.4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "                                  ADVANCED RESUME SCREENING SYSTEM                                  \n",
            "                      with TF-IDF, NER, Experience Extraction & Visualization                       \n",
            "====================================================================================================\n",
            "\n",
            "Loading skills database from /content/drive/MyDrive/CDS_PROJECT/skills_db.json...\n",
            "====================================================================================================\n",
            "STEP 1: JOB DESCRIPTION\n",
            "====================================================================================================\n",
            "\n",
            "Options:\n",
            "1. Use default job description (Senior Software Engineer - ML)\n",
            "2. Enter custom job description\n",
            "3. Load from file\n",
            "\n",
            "Enter your choice (1/2/3) [default: 1]: 1\n",
            "\n",
            "====================================================================================================\n",
            "STEP 2: RESUME FOLDER\n",
            "====================================================================================================\n",
            "\n",
            "Enter path to resume folder [default: ./resumes]: /content/drive/MyDrive/CDS_PROJECT/Resumes\n",
            "\n",
            "====================================================================================================\n",
            "STEP 3: SCREENING PARAMETERS\n",
            "====================================================================================================\n",
            "\n",
            "Enter number of top candidates to shortlist [default: 5]: 4\n",
            "\n",
            "Use custom scoring weights? (y/n) [default: n]: n\n",
            "\n",
            "====================================================================================================\n",
            "PROCESSING RESUMES...\n",
            "====================================================================================================\n",
            "Parsing Job Description...\n",
            "\n",
            "================================================================================\n",
            "JOB DESCRIPTION ANALYSIS\n",
            "================================================================================\n",
            "Required Skills: 25\n",
            "Skills: git, ci/cd, java, python, communication, aws, postgresql, sql, computer vision, analytical...\n",
            "Required Experience: 5 years\n",
            "Required Education: Masters\n",
            "================================================================================\n",
            "\n",
            "Processing 5 resumes...\n",
            "\n",
            "Analyzing 1/5: Om_Patel_CV.pdf\n",
            "Analyzing 2/5: VED_CV.docx.pdf\n",
            "Analyzing 3/5: Het_Resume_NEW.pdf\n",
            "Analyzing 4/5: Stuti-Resume.pdf\n",
            "Analyzing 5/5: Dilon Resume.pdf\n",
            "\n",
            "====================================================================================================\n",
            "                                    TOP 4 SHORTLISTED CANDIDATES                                    \n",
            "====================================================================================================\n",
            "\n",
            "                                              RANK #1                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Gohil\n",
            "+91\n",
            "Resume File:              Stuti-Resume.pdf\n",
            "Email:                    sng19.work@gmail.com\n",
            "Phone:                    +91 6355046464\n",
            "\n",
            "SCORES:                  \n",
            "  Composite Score:        0.4311 (43.1%)\n",
            "  Skills (Jaccard) Score: 0.3684 (36.8%)\n",
            "  Semantic (Cosine) Score: 0.1325 (13.2%)\n",
            "  Experience Score:       0.7200 (72.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             3.6 years (JD: 5 yrs)\n",
            "  Education:              Masters (JD: Masters)\n",
            "  Matched Skills:         14 of 25 (56.0%)\n",
            "  Total Skills:           27\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          python, agile, docker, communication, aws\n",
            "                          gcp, scikit-learn, sql, git, machine learning\n",
            "                          ci/cd, tensorflow, pytorch, cloud\n",
            "\n",
            "                                              RANK #2                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Patel\n",
            "Resume File:              Om_Patel_CV.pdf\n",
            "Email:                    naimesh2003@gmail.com\n",
            "Phone:                    +91-9104228197\n",
            "\n",
            "SCORES:                  \n",
            "  Composite Score:        0.3444 (34.4%)\n",
            "  Skills (Jaccard) Score: 0.0909 (9.1%)\n",
            "  Semantic (Cosine) Score: 0.0267 (2.7%)\n",
            "  Experience Score:       1.0000 (100.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             6.1 years (JD: 5 yrs)\n",
            "  Education:              Masters (JD: Masters)\n",
            "  Matched Skills:         3 of 25 (12.0%)\n",
            "  Total Skills:           11\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          git, mysql, communication\n",
            "\n",
            "                                              RANK #3                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Samaj\n",
            "Resume File:              Het_Resume_NEW.pdf\n",
            "Email:                    hetvirani1305@gmail.com\n",
            "Phone:                    +91-9313917798\n",
            "\n",
            "SCORES:                  \n",
            "  Composite Score:        0.2037 (20.4%)\n",
            "  Skills (Jaccard) Score: 0.2143 (21.4%)\n",
            "  Semantic (Cosine) Score: 0.0334 (3.3%)\n",
            "  Experience Score:       0.0400 (4.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             0.2 years (JD: 5 yrs)\n",
            "  Education:              Masters (JD: Masters)\n",
            "  Matched Skills:         6 of 25 (24.0%)\n",
            "  Total Skills:           9\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          communication, postgresql, mysql, java, teamwork\n",
            "                          cloud\n",
            "\n",
            "                                              RANK #4                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Dilon Brahmbhatt\n",
            "Resume File:              Dilon Resume.pdf\n",
            "Email:                    dilon151103@gmail.com\n",
            "Phone:                    +91-8320137058\n",
            "\n",
            "SCORES:                  \n",
            "  Composite Score:        0.1752 (17.5%)\n",
            "  Skills (Jaccard) Score: 0.1481 (14.8%)\n",
            "  Semantic (Cosine) Score: 0.0263 (2.6%)\n",
            "  Experience Score:       0.0400 (4.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             0.2 years (JD: 5 yrs)\n",
            "  Education:              Masters (JD: Masters)\n",
            "  Matched Skills:         4 of 25 (16.0%)\n",
            "  Total Skills:           6\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          mysql, python, cloud, communication\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "SAVING RESULTS...\n",
            "====================================================================================================\n",
            "✓ Results saved to screening_results.csv\n",
            "✓ HTML report saved to screening_report.html\n",
            "\n",
            "====================================================================================================\n",
            "GENERATING VISUALIZATIONS...\n",
            "====================================================================================================\n",
            "\n",
            "Generate visualizations? (y/n) [default: y]: y\n",
            "✓ Saved: visualizations/1_composite_scores.png\n",
            "✓ Saved: visualizations/2_score_breakdown.png\n",
            "✓ Saved: visualizations/3_skills_match.png\n",
            "✓ Saved: visualizations/4_experience_vs_score.png\n",
            "✓ Saved: visualizations/5_education_distribution.png\n",
            "✓ Saved: visualizations/6_radar_chart.png\n",
            "\n",
            "✓ All visualizations saved in 'visualizations' folder!\n",
            "\n",
            "====================================================================================================\n",
            "                                ✓ SCREENING COMPLETED SUCCESSFULLY!                                 \n",
            "====================================================================================================\n",
            "\n",
            "Generated Files:\n",
            "  📊 screening_results.csv - Detailed results for ALL candidates\n",
            "  📄 screening_report.html - Interactive report of TOP candidates\n",
            "  📈 visualizations/ - Folder containing all charts and graphs\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NEW**"
      ],
      "metadata": {
        "id": "CIgUWQ8AyY_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Advanced Resume Screening and Shortlisting System (Upgraded v3 - Academic Evaluation)\n",
        "\n",
        "Features:\n",
        "- NLP, NER, TF-IDF, Cosine Similarity\n",
        "- Robust Experience/Name Extraction\n",
        "- Visualization\n",
        "- Scoring formula based on academic paper (0.6 * Cosine + 0.4 * Jaccard)\n",
        "- Skill extraction accuracy evaluation function\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import pdfplumber\n",
        "import logging\n",
        "import warnings # To handle the matplotlib warning\n",
        "\n",
        "# Suppress noisy logs from pdfminer (used by pdfplumber)\n",
        "logging.getLogger('pdfminer').setLevel(logging.ERROR)\n",
        "\n",
        "# --- NLTK Data Downloads ---\n",
        "def download_nltk_data():\n",
        "    \"\"\"Download required NLTK data models if not found.\"\"\"\n",
        "    nltk_packages = [\n",
        "        ('tokenizers/punkt', 'punkt'),\n",
        "        ('tokenizers/punkt_tab', 'punkt_tab'),\n",
        "        ('corpora/stopwords', 'stopwords'),\n",
        "        ('corpora/wordnet', 'wordnet'),\n",
        "        ('corpora/omw-1.4', 'omw-1.4')\n",
        "    ]\n",
        "    for path, package_id in nltk_packages:\n",
        "        try:\n",
        "            nltk.data.find(path)\n",
        "        except LookupError:\n",
        "            print(f\"Downloading NLTK package: {package_id}...\")\n",
        "            nltk.download(package_id)\n",
        "\n",
        "download_nltk_data()\n",
        "\n",
        "# --- Load spaCy model for NER ---\n",
        "def load_spacy_model(model_name=\"en_core_web_sm\"):\n",
        "    \"\"\"Load or download spaCy model.\"\"\"\n",
        "    try:\n",
        "        nlp = spacy.load(model_name)\n",
        "    except:\n",
        "        print(f\"Downloading spaCy model: {model_name}...\")\n",
        "        os.system(f\"python -m spacy download {model_name}\")\n",
        "        nlp = spacy.load(model_name)\n",
        "    return nlp\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "\n",
        "class AdvancedResumeScreener:\n",
        "    \"\"\"\n",
        "    Advanced Resume Screening System with NER, TF-IDF, Experience, Education, and Visualization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, skills_db_path='skills_db.json'):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english')) - {'and', 'to', 'of'}\n",
        "        self.nlp = nlp\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "\n",
        "        # Blacklist for common non-name headers\n",
        "        self.NAME_BLACKLIST = {\n",
        "            'linkedin', 'github', 'portfolio', 'profile', 'leetcode', 'email', 'phone',\n",
        "            'address', 'resume', 'cv', 'work', 'contact', 'experience', 'education',\n",
        "            'skills', 'projects', 'summary'\n",
        "        }\n",
        "\n",
        "        # Education degrees\n",
        "        self.education_keywords = {\n",
        "            'phd': ['phd', 'ph.d', 'doctorate', 'doctoral'],\n",
        "            'masters': ['masters', 'master', 'msc', 'm.sc', 'ma', 'm.a', 'mba', 'm.b.a', 'mtech', 'm.tech'],\n",
        "            'bachelors': ['bachelors', 'bachelor', 'bsc', 'b.sc', 'ba', 'b.a', 'btech', 'b.tech', 'be', 'b.e'],\n",
        "            'diploma': ['diploma', 'associate']\n",
        "        }\n",
        "\n",
        "        # Load skills from external JSON\n",
        "        self.technical_skills = self.load_skills_from_json(skills_db_path)\n",
        "\n",
        "        # Initialize TF-IDF Vectorizer\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2)  # Capture single words and two-word phrases\n",
        "        )\n",
        "\n",
        "    def load_skills_from_json(self, json_path):\n",
        "        \"\"\"Loads the skills database from an external JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                print(f\"Loading skills database from {json_path}...\")\n",
        "                return json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {json_path} not found. Using empty skills DB.\")\n",
        "            return {}\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error: Could not decode {json_path}. Using empty skills DB.\")\n",
        "            return {}\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract text from PDF resume using pdfplumber for better layout handling\"\"\"\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    # Extract text, respecting layout\n",
        "                    page_text = page.extract_text(x_tolerance=2, y_tolerance=2)\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {pdf_path} with pdfplumber: {str(e)}\")\n",
        "            return \"\"  # Return empty string on failure\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Preprocess text with cleaning, tokenization, and lemmatization\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\\\x[a-f0-9]{2}', '', text)  # Remove hex characters\n",
        "        text = re.sub(r'\\\\[abtnr]', '', text)     # Remove escape sequences\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)       # Remove punctuation\n",
        "        text = re.sub(r'\\s+', ' ', text)           # Condense whitespace\n",
        "\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 1]\n",
        "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def extract_contact_info_and_name(self, text, doc):\n",
        "        \"\"\"\n",
        "        Extracts contact info using regex and a robust, multi-step name extraction logic\n",
        "        \"\"\"\n",
        "        info = {\n",
        "            'name': 'Unknown',\n",
        "            'email': 'N/A',\n",
        "            'phone': 'N/A'\n",
        "        }\n",
        "\n",
        "        # --- 1. Extract Name (More Robust Multi-Step Logic) ---\n",
        "\n",
        "        # Step 1: High-Confidence Search\n",
        "        # Look for a 'PERSON' entity in the first 75 tokens (the top of the resume)\n",
        "        person_entities = [ent.text for ent in doc[:75].ents if ent.label_ == 'PERSON']\n",
        "        if person_entities:\n",
        "            info['name'] = person_entities[0] # Take the first one\n",
        "\n",
        "        # Step 2: Blacklist Check\n",
        "        # Check if the found name is likely a header (e.g., \"LinkedIn\")\n",
        "        name_parts = set(info['name'].lower().split())\n",
        "        if info['name'] == 'Unknown' or name_parts.intersection(self.NAME_BLACKLIST):\n",
        "            # Name is \"Unknown\" OR it's a blacklisted word, so we reset and try Fallback 1\n",
        "            info['name'] = 'Unknown'\n",
        "\n",
        "            # Fallback 1: Try the Proper Noun (PROPN) Matcher\n",
        "            pattern1 = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "            pattern2 = [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "\n",
        "            if \"NAME_PATTERN_1\" not in self.matcher._patterns:\n",
        "                self.matcher.add(\"NAME_PATTERN_1\", [pattern1], on_match=None)\n",
        "            if \"NAME_PATTERN_2\" not in self.matcher._patterns:\n",
        "                self.matcher.add(\"NAME_PATTERN_2\", [pattern2], on_match=None)\n",
        "\n",
        "            matches = self.matcher(doc[:75])\n",
        "            if matches:\n",
        "                matches.sort(key=lambda x: x[2] - x[1], reverse=True) # Get longest match\n",
        "                match_id, start, end = matches[0]\n",
        "                potential_name = doc[start:end].text\n",
        "\n",
        "                # Check blacklist *again*\n",
        "                potential_name_parts = set(potential_name.lower().split())\n",
        "                if not potential_name_parts.intersection(self.NAME_BLACKLIST):\n",
        "                    info['name'] = potential_name\n",
        "\n",
        "        # Fallback 2: Last Resort\n",
        "        # If name is *still* Unknown, search the *entire document* for the first PERSON entity\n",
        "        if info['name'] == 'Unknown':\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == 'PERSON':\n",
        "                    name_parts = set(ent.text.lower().split())\n",
        "                    if not name_parts.intersection(self.NAME_BLACKLIST):\n",
        "                        info['name'] = ent.text\n",
        "                        break  # Take the first valid one\n",
        "\n",
        "        # --- 2. Extract Email ---\n",
        "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "        email_match = re.search(email_pattern, text)\n",
        "        if email_match:\n",
        "            info['email'] = email_match.group(0)\n",
        "\n",
        "        # --- 3. Extract Phone ---\n",
        "        phone_pattern = r'(\\(?\\+?\\d{1,3}\\)?[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?[\\d\\s-]{10,15}\\b'\n",
        "        phone_match = re.search(phone_pattern, text)\n",
        "        if phone_match:\n",
        "            info['phone'] = phone_match.group(0).strip()\n",
        "\n",
        "        return info\n",
        "\n",
        "    def extract_experience(self, text):\n",
        "        \"\"\"\n",
        "        Extract years of experience from resume by parsing date ranges.\n",
        "        \"\"\"\n",
        "        date_range_pattern = re.compile(\n",
        "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\w.]{0,6}\\s+\\d{4}|'  # Month YYYY\n",
        "            r'\\d{1,2}[\\/.-]\\d{4}|'  # MM/YYYY\n",
        "            r'\\b\\d{4}\\b)'  # YYYY\n",
        "            r'\\s*(?:[-–—toTO])\\s*'\n",
        "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\w.]{0,6}\\s+\\d{4}|'  # Month YYYY\n",
        "            r'\\d{1,2}[\\/.-]\\d{4}|'  # MM/YYYY\n",
        "            r'\\b\\d{4}\\b|'  # YYYY\n",
        "            r'Present|Current|Till Date|Now)',  # Present\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "        matches = date_range_pattern.findall(text)\n",
        "        if not matches:\n",
        "            exp_patterns = r'(\\d+)\\+?\\s*(?:years?|yrs?)\\s*(?:of)?\\s*experience'\n",
        "            exp_match = re.search(exp_patterns, text.lower())\n",
        "            if exp_match:\n",
        "                return {'total_years': int(exp_match.group(1))}\n",
        "            return {'total_years': 0}\n",
        "\n",
        "        month_map = {\n",
        "            'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
        "            'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "        }\n",
        "        def parse_date(date_str):\n",
        "            date_str = date_str.lower().strip().replace('.', '')\n",
        "            if date_str in ['present', 'current', 'till date', 'now']:\n",
        "                return datetime.now()\n",
        "            for month_name, month_num in month_map.items():\n",
        "                if date_str.startswith(month_name):\n",
        "                    year_match = re.search(r'(\\d{4})', date_str)\n",
        "                    if year_match:\n",
        "                        return datetime(int(year_match.group(1)), month_num, 1)\n",
        "            match = re.match(r'(\\d{1,2})[\\/.-](\\d{4})', date_str)\n",
        "            if match:\n",
        "                return datetime(int(match.group(2)), int(match.group(1)), 1)\n",
        "            match = re.match(r'^(\\d{4})$', date_str)\n",
        "            if match:\n",
        "                return datetime(int(match.group(1)), 1, 1)\n",
        "            return None\n",
        "\n",
        "        parsed_ranges = []\n",
        "        for start_str, end_str in matches:\n",
        "            start_date = parse_date(start_str)\n",
        "            end_date = parse_date(end_str)\n",
        "            if start_date and end_date:\n",
        "                parsed_ranges.append((start_date, end_date))\n",
        "        if not parsed_ranges:\n",
        "            return {'total_years': 0}\n",
        "\n",
        "        parsed_ranges.sort(key=lambda x: x[0])\n",
        "        merged_ranges = []\n",
        "        if parsed_ranges:\n",
        "            merged_ranges = [parsed_ranges[0]]\n",
        "            for current_start, current_end in parsed_ranges[1:]:\n",
        "                last_start, last_end = merged_ranges[-1]\n",
        "                if current_start <= last_end:\n",
        "                    new_end = max(last_end, current_end)\n",
        "                    merged_ranges[-1] = (last_start, new_end)\n",
        "                else:\n",
        "                    merged_ranges.append((current_start, current_end))\n",
        "\n",
        "        total_months = 0\n",
        "        for start_date, end_date in merged_ranges:\n",
        "            months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
        "            total_months += (months + 1)\n",
        "\n",
        "        return {'total_years': round(total_months / 12, 1)}\n",
        "\n",
        "    def extract_education(self, text, doc):\n",
        "        \"\"\"Extract education qualifications from resume\"\"\"\n",
        "        education_info = {\n",
        "            'highest_degree': 'None',\n",
        "            'degrees': [],\n",
        "            'institutions': []\n",
        "        }\n",
        "        text_lower = text.lower()\n",
        "        degree_priority = ['phd', 'masters', 'bachelors', 'diploma']\n",
        "        for degree in degree_priority:\n",
        "            for keyword in self.education_keywords[degree]:\n",
        "                if keyword in text_lower:\n",
        "                    if education_info['highest_degree'] == 'None':\n",
        "                        education_info['highest_degree'] = degree.title()\n",
        "                    if degree.title() not in education_info['degrees']:\n",
        "                        education_info['degrees'].append(degree.title())\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'ORG':\n",
        "                org_lower = ent.text.lower()\n",
        "                if any(word in org_lower for word in ['university', 'college', 'institute', 'school']):\n",
        "                    if ent.text not in education_info['institutions']:\n",
        "                        education_info['institutions'].append(ent.text)\n",
        "        education_info['institutions'] = list(set(education_info['institutions']))\n",
        "        return education_info\n",
        "\n",
        "    def extract_skills(self, text, custom_skills=None):\n",
        "        \"\"\"Extract skills from text with categorization\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_skills = {'all_skills': [], 'by_category': {}}\n",
        "        skills_db = custom_skills if custom_skills else self.technical_skills\n",
        "        for category, skills in skills_db.items():\n",
        "            found_in_category = []\n",
        "            for skill in skills:\n",
        "                if ' ' in skill:\n",
        "                    if skill.lower() in text_lower:\n",
        "                        found_in_category.append(skill)\n",
        "                else:\n",
        "                    if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text_lower):\n",
        "                        found_in_category.append(skill)\n",
        "            for skill in found_in_category:\n",
        "                if skill not in found_skills['all_skills']:\n",
        "                    found_skills['all_skills'].append(skill)\n",
        "            if found_in_category:\n",
        "                found_skills['by_category'][category] = list(set(found_in_category))\n",
        "        found_skills['all_skills'] = list(set(found_skills['all_skills']))\n",
        "        return found_skills\n",
        "\n",
        "    def calculate_jaccard_similarity(self, set1, set2):\n",
        "        \"\"\"Calculate Jaccard Similarity: J(A,B) = |A ∩ B| / |A ∪ B|\"\"\"\n",
        "        set1 = set([s.lower() for s in set1])\n",
        "        set2 = set([s.lower() for s in set2])\n",
        "        intersection = len(set1.intersection(set2))\n",
        "        union = len(set1.union(set2))\n",
        "        return intersection / union if union > 0 else 0.0\n",
        "\n",
        "    def calculate_composite_score(self, jd_info, resume_info, cosine_score, weights):\n",
        "        \"\"\"\n",
        "        Calculate composite score based on the flexible weights provided.\n",
        "        Also calculates individual scores for reporting.\n",
        "        \"\"\"\n",
        "\n",
        "        # --- 1. Calculate Jaccard Skill Score (for scoring) ---\n",
        "        skills_score = self.calculate_jaccard_similarity(\n",
        "            jd_info['skills']['all_skills'],\n",
        "            resume_info['skills']['all_skills']\n",
        "        )\n",
        "\n",
        "        # --- 2. Calculate Experience Score (for reporting or scoring) ---\n",
        "        exp_score = 0\n",
        "        if 'required_experience' in jd_info and jd_info['required_experience'] > 0:\n",
        "            exp_ratio = min(resume_info['experience']['total_years'] / jd_info['required_experience'], 1.0)\n",
        "            exp_score = exp_ratio\n",
        "        else:\n",
        "            exp_score = min(resume_info['experience']['total_years'] / 5.0, 1.0)\n",
        "\n",
        "        # --- 3. Calculate Education Score (for reporting or scoring) ---\n",
        "        edu_score = 0\n",
        "        degree_hierarchy = {'None': 0, 'Diploma': 1, 'Bachelors': 2, 'Masters': 3, 'Phd': 4}\n",
        "        if 'required_education' in jd_info and jd_info['required_education'] != 'None':\n",
        "            required_level = degree_hierarchy.get(jd_info['required_education'], 0)\n",
        "            candidate_level = degree_hierarchy.get(resume_info['education']['highest_degree'], 0)\n",
        "            if candidate_level >= required_level:\n",
        "                edu_score = 1.0\n",
        "            elif required_level > 0:\n",
        "                edu_score = candidate_level / required_level\n",
        "            else:\n",
        "                edu_score = 0.5\n",
        "        else:\n",
        "            edu_score = min(degree_hierarchy.get(resume_info['education']['highest_degree'], 0) / 3.0, 1.0)\n",
        "\n",
        "        # --- 4. Calculate Final Hybrid Score ---\n",
        "        # This dynamically calculates the score based on the weights dict passed from main()\n",
        "        # If a weight isn't in the dict (e.g., 'experience'), it defaults to 0 and adds nothing.\n",
        "        final_score = (\n",
        "            weights.get('cosine', 0) * cosine_score +\n",
        "            weights.get('skills', 0) * skills_score +\n",
        "            weights.get('experience', 0) * exp_score +\n",
        "            weights.get('education', 0) * edu_score\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'composite_score': final_score,\n",
        "            'skills_score': skills_score,      # This is the Jaccard Score\n",
        "            'cosine_score': cosine_score,      # This is the TF-IDF Cosine Score\n",
        "            'experience_score': exp_score,    # For reporting\n",
        "            'education_score': edu_score      # For reporting\n",
        "        }\n",
        "\n",
        "    def parse_job_description(self, jd_text):\n",
        "        \"\"\"Parse job description to extract requirements\"\"\"\n",
        "        doc = self.nlp(jd_text)\n",
        "        jd_info = {\n",
        "            'text': jd_text,\n",
        "            'processed_text': self.preprocess_text(jd_text),\n",
        "            'skills': self.extract_skills(jd_text),\n",
        "            'experience': self.extract_experience(jd_text),\n",
        "            'education': self.extract_education(jd_text, doc),\n",
        "            'contact_info': self.extract_contact_info_and_name(jd_text, doc)\n",
        "        }\n",
        "        jd_info['required_experience'] = jd_info['experience']['total_years']\n",
        "        jd_info['required_education'] = jd_info['education']['highest_degree']\n",
        "        return jd_info\n",
        "\n",
        "    def screen_resumes(self, job_description, resume_folder, top_n=5, weights=None):\n",
        "        \"\"\"\n",
        "        Screen resumes with advanced analysis.\n",
        "        Uses the 'weights' dict passed from main() for scoring.\n",
        "        \"\"\"\n",
        "        # Default to paper's formula if no weights are provided\n",
        "        if weights is None:\n",
        "            weights = {'cosine': 0.6, 'skills': 0.4}\n",
        "\n",
        "        # Parse job description\n",
        "        print(\"Parsing Job Description...\")\n",
        "        jd_info = self.parse_job_description(job_description)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"JOB DESCRIPTION ANALYSIS\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Required Skills: {len(jd_info['skills']['all_skills'])}\")\n",
        "        print(f\"Skills: {', '.join(jd_info['skills']['all_skills'][:10])}...\")\n",
        "        print(f\"Required Experience: {jd_info['required_experience']} years\")\n",
        "        print(f\"Required Education: {jd_info['required_education']}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        # Process all resumes\n",
        "        results = []\n",
        "        pdf_files = [f for f in os.listdir(resume_folder) if f.endswith('.pdf')]\n",
        "        if not pdf_files:\n",
        "            print(\"No PDF files found in the folder!\")\n",
        "            return pd.DataFrame(), jd_info, pd.DataFrame()\n",
        "\n",
        "        print(f\"Processing {len(pdf_files)} resumes...\\n\")\n",
        "\n",
        "        # --- Prepare for Cosine Similarity ---\n",
        "        resume_texts = []\n",
        "        valid_pdf_files = []\n",
        "        for pdf_file in pdf_files:\n",
        "            pdf_path = os.path.join(resume_folder, pdf_file)\n",
        "            resume_text = self.extract_text_from_pdf(pdf_path)\n",
        "            if resume_text:\n",
        "                resume_texts.append(resume_text)\n",
        "                valid_pdf_files.append(pdf_file)\n",
        "            else:\n",
        "                 print(f\"Skipping {pdf_file}: Could not extract text.\")\n",
        "        if not resume_texts:\n",
        "            print(\"No resumes could be read.\")\n",
        "            return pd.DataFrame(), jd_info, pd.DataFrame()\n",
        "\n",
        "        jd_processed = jd_info['processed_text']\n",
        "        resumes_processed = [self.preprocess_text(t) for t in resume_texts]\n",
        "\n",
        "        corpus = [jd_processed] + resumes_processed\n",
        "        self.tfidf_vectorizer.fit(corpus)\n",
        "        jd_vector = self.tfidf_vectorizer.transform([jd_processed])\n",
        "        resumes_vector = self.tfidf_vectorizer.transform(resumes_processed)\n",
        "\n",
        "        cosine_scores = cosine_similarity(jd_vector, resumes_vector)[0]\n",
        "\n",
        "        # --- Loop and analyze each resume ---\n",
        "        for idx, pdf_file in enumerate(valid_pdf_files):\n",
        "            print(f\"Analyzing {idx+1}/{len(valid_pdf_files)}: {pdf_file}\")\n",
        "\n",
        "            resume_text = resume_texts[idx]\n",
        "            resume_processed = resumes_processed[idx]\n",
        "            doc = self.nlp(resume_text)\n",
        "\n",
        "            # Analyze resume\n",
        "            resume_info = {\n",
        "                'text': resume_text,\n",
        "                'processed_text': resume_processed,\n",
        "                'contact_info': self.extract_contact_info_and_name(resume_text, doc),\n",
        "                'skills': self.extract_skills(resume_text),\n",
        "                'experience': self.extract_experience(resume_text),\n",
        "                'education': self.extract_education(resume_text, doc)\n",
        "            }\n",
        "\n",
        "            cosine_score = cosine_scores[idx]\n",
        "            # Pass the weights from main() into the scoring function\n",
        "            scores = self.calculate_composite_score(jd_info, resume_info, cosine_score, weights)\n",
        "\n",
        "            matched_skills = list(set([s.lower() for s in jd_info['skills']['all_skills']]).intersection(\n",
        "                set([s.lower() for s in resume_info['skills']['all_skills']])\n",
        "            ))\n",
        "\n",
        "            results.append({\n",
        "                'Resume': pdf_file,\n",
        "                'Candidate_Name': resume_info['contact_info']['name'],\n",
        "                'Composite_Score': scores['composite_score'],\n",
        "                'Cosine_Score': scores['cosine_score'],\n",
        "                'Skills_Score': scores['skills_score'],\n",
        "                'Experience_Score': scores['experience_score'],\n",
        "                'Education_Score': scores['education_score'],\n",
        "                'Total_Years_Experience': resume_info['experience']['total_years'],\n",
        "                'Highest_Degree': resume_info['education']['highest_degree'],\n",
        "                'Matched_Skills': len(matched_skills),\n",
        "                'Total_JD_Skills': len(jd_info['skills']['all_skills']),\n",
        "                'Total_Resume_Skills': len(resume_info['skills']['all_skills']),\n",
        "                'Skills_List': ', '.join(matched_skills),\n",
        "                'Match_Percentage': (len(matched_skills) / len(jd_info['skills']['all_skills']) * 100) if len(jd_info['skills']['all_skills']) > 0 else 0,\n",
        "                'Email': resume_info['contact_info']['email'],\n",
        "                'Phone': resume_info['contact_info']['phone'],\n",
        "                'Skills_By_Category': json.dumps(resume_info['skills']['by_category'])\n",
        "            })\n",
        "\n",
        "        df_results = pd.DataFrame(results)\n",
        "        df_results = df_results.sort_values('Composite_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        return df_results.head(top_n), jd_info, df_results # Return all results\n",
        "\n",
        "    def visualize_results(self, all_results_df, jd_info, output_folder='visualizations'):\n",
        "        \"\"\"Create comprehensive visualizations of screening results\"\"\"\n",
        "        if all_results_df.empty:\n",
        "            print(\"No results to visualize!\")\n",
        "            return\n",
        "\n",
        "        results_df = all_results_df.head(15) # Use top 15 for readable charts\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "        # 1. Composite Score Comparison (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, max(8, len(results_df) * 0.5)))\n",
        "        candidates = [f\"{row['Candidate_Name']}\\n({row['Resume']})\" for _, row in results_df.iterrows()]\n",
        "        scores = results_df['Composite_Score'].values\n",
        "        colors = sns.color_palette(\"RdYlGn\", len(candidates))\n",
        "        bars = ax.barh(candidates, scores, color=colors)\n",
        "        ax.set_xlabel('Composite Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title(f'Top {len(results_df)} Candidates - Composite Score Ranking', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.set_xlim(0, 1)\n",
        "        ax.invert_yaxis()\n",
        "        for i, (bar, score) in enumerate(zip(bars, scores)):\n",
        "            ax.text(score + 0.01, bar.get_y() + bar.get_height()/2, f'{score:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/1_composite_scores.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/1_composite_scores.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 2. Multi-dimensional Score Breakdown (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "        df_melted = results_df.melt(\n",
        "            id_vars='Candidate_Name',\n",
        "            value_vars=['Skills_Score', 'Cosine_Score', 'Experience_Score', 'Education_Score'],\n",
        "            var_name='Score_Type',\n",
        "            value_name='Score'\n",
        "        )\n",
        "        sns.barplot(x='Candidate_Name', y='Score', hue='Score_Type', data=df_melted, ax=ax, palette='Set2')\n",
        "        ax.set_xlabel('Candidates', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Score Breakdown by Dimension', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "        plt.setp(ax.get_xticklabels(), ha='right')\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.set_ylim(0, 1)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/2_score_breakdown.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/2_score_breakdown.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 3. Skills Match Visualization (Top N)\n",
        "        fig, ax = plt.subplots(figsize=(14, max(8, len(results_df) * 0.5)))\n",
        "        candidates_short = [row['Candidate_Name'] for _, row in results_df.iterrows()]\n",
        "        matched = results_df['Matched_Skills'].values\n",
        "        total_jd = results_df['Total_JD_Skills'].values[0] if len(results_df) > 0 else 0\n",
        "        unmatched = [total_jd - m for m in matched]\n",
        "        bars1 = ax.barh(candidates_short, matched, label='Matched Skills', color='#27ae60')\n",
        "        bars2 = ax.barh(candidates_short, unmatched, left=matched, label='Unmatched Skills (JD)', color='#ecf0f1')\n",
        "        ax.set_xlabel('Number of Skills', fontsize=12, fontweight='bold')\n",
        "        ax.set_title(f'Skills Match Analysis (Total Required: {total_jd})', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.invert_yaxis()\n",
        "        for i, (m, u) in enumerate(zip(matched, unmatched)):\n",
        "            percentage = (m / total_jd * 100) if total_jd > 0 else 0\n",
        "            ax.text(m/2, i, f'{m}', ha='center', va='center', fontweight='bold', color='white')\n",
        "            ax.text(m + u + 0.5, i, f'{percentage:.1f}%', ha='left', va='center', fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/3_skills_match.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/3_skills_match.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 4. Experience vs Score Scatter (All Candidates)\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        scatter = ax.scatter(all_results_df['Total_Years_Experience'],\n",
        "                             all_results_df['Composite_Score'],\n",
        "                             s=100, alpha=0.6, c=all_results_df['Composite_Score'],\n",
        "                             cmap='viridis', edgecolors='black', linewidth=1)\n",
        "        for idx, row in all_results_df.head(5).iterrows():\n",
        "            ax.annotate(row['Candidate_Name'],\n",
        "                       (row['Total_Years_Experience'], row['Composite_Score']),\n",
        "                       xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
        "        if jd_info['required_experience'] > 0:\n",
        "            ax.axvline(x=jd_info['required_experience'], color='red', linestyle='--', label=f'JD Req: {jd_info[\"required_experience\"]} yrs')\n",
        "            ax.legend()\n",
        "        ax.set_xlabel('Years of Experience', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Composite Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Experience vs Composite Score (All Candidates)', fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.colorbar(scatter, ax=ax, label='Composite Score')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/4_experience_vs_score.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/4_experience_vs_score.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 5. Education Distribution (All Candidates)\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        edu_counts = all_results_df['Highest_Degree'].value_counts()\n",
        "        colors_pie = sns.color_palette(\"Set2\", len(edu_counts))\n",
        "        wedges, texts, autotexts = ax.pie(edu_counts.values, labels=edu_counts.index,\n",
        "                                          autopct='%1.1f%%', startangle=90,\n",
        "                                          colors=colors_pie, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
        "        ax.set_title('Education Level Distribution (All Candidates)', fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_folder}/5_education_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Saved: {output_folder}/5_education_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 6. Radar Chart for Top 3 Candidates\n",
        "        if len(results_df) >= 3:\n",
        "            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "            categories = ['Skills (Jaccard)', 'Semantic (Cosine)', 'Experience', 'Education']\n",
        "            num_vars = len(categories)\n",
        "            angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "            angles += angles[:1]\n",
        "            ax.set_theta_offset(np.pi / 2)\n",
        "            ax.set_theta_direction(-1)\n",
        "            ax.set_xticks(angles[:-1])\n",
        "            ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n",
        "            colors_radar = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "            for idx in range(min(3, len(results_df))):\n",
        "                row = results_df.iloc[idx]\n",
        "                values = [row['Skills_Score'], row['Cosine_Score'], row['Experience_Score'], row['Education_Score']]\n",
        "                values += values[:1]\n",
        "                ax.plot(angles, values, 'o-', linewidth=2, label=row['Candidate_Name'], color=colors_radar[idx])\n",
        "                ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.set_title('Top 3 Candidates - Profile Radar', fontsize=14, fontweight='bold', pad=30)\n",
        "            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{output_folder}/6_radar_chart.png', dpi=300, bbox_inches='tight')\n",
        "            print(f\"✓ Saved: {output_folder}/6_radar_chart.png\")\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\n✓ All visualizations saved in '{output_folder}' folder!\")\n",
        "\n",
        "    def display_results(self, results_df, jd_info):\n",
        "        \"\"\"Display detailed screening results\"\"\"\n",
        "        if results_df.empty:\n",
        "            print(\"No results to display!\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"{'TOP ' + str(len(results_df)) + ' SHORTLISTED CANDIDATES':^100}\")\n",
        "        print(\"=\"*100)\n",
        "        for idx, row in results_df.iterrows():\n",
        "            rank = idx + 1\n",
        "            print(f\"\\n{'RANK #' + str(rank):^100}\")\n",
        "            print(\"-\" * 100)\n",
        "            print(f\"{'Candidate:':<25} {row['Candidate_Name']}\")\n",
        "            print(f\"{'Resume File:':<25} {row['Resume']}\")\n",
        "            print(f\"{'Email:':<25} {row['Email']}\")\n",
        "            print(f\"{'Phone:':<25} {row['Phone']}\")\n",
        "            print()\n",
        "            print(f\"{'SCORES:':<25}\")\n",
        "            print(f\"{'  Hybrid Score:':<25} {row['Composite_Score']:.4f} ({row['Composite_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Skills (Jaccard) Score:':<25} {row['Skills_Score']:.4f} ({row['Skills_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Semantic (Cosine) Score:':<25} {row['Cosine_Score']:.4f} ({row['Cosine_Score']*100:.1f}%)\")\n",
        "            print()\n",
        "            print(f\"{'OTHER METRICS (for info):':<25}\")\n",
        "            print(f\"{'  Experience Score:':<25} {row['Experience_Score']:.4f} ({row['Experience_Score']*100:.1f}%)\")\n",
        "            print(f\"{'  Education Score:':<25} {row['Education_Score']:.4f} ({row['Education_Score']*100:.1f}%)\")\n",
        "            print()\n",
        "            print(f\"{'QUALIFICATIONS:':<25}\")\n",
        "            print(f\"{'  Experience:':<25} {row['Total_Years_Experience']} years (JD: {jd_info['required_experience']} yrs)\")\n",
        "            print(f\"{'  Education:':<25} {row['Highest_Degree']} (JD: {jd_info['required_education']})\")\n",
        "            print(f\"{'  Matched Skills:':<25} {row['Matched_Skills']} of {row['Total_JD_Skills']} ({row['Match_Percentage']:.1f}%)\")\n",
        "            print()\n",
        "            print(f\"{'MATCHED SKILLS:':<25}\")\n",
        "            skills_list = row['Skills_List'].split(', ') if row['Skills_List'] else [\"None\"]\n",
        "            for i in range(0, len(skills_list), 5):\n",
        "                print(f\"{'  ':<25} {', '.join(skills_list[i:i+5])}\")\n",
        "        print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
        "\n",
        "    def save_results(self, results_df, output_file='screening_results.csv'):\n",
        "        \"\"\"Save detailed results to CSV\"\"\"\n",
        "        results_df.to_csv(output_file, index=False)\n",
        "        print(f\"✓ Results saved to {output_file}\")\n",
        "\n",
        "    def generate_report(self, results_df, jd_info, all_results_df, output_file='screening_report.html'):\n",
        "        \"\"\"Generate HTML report with all results\"\"\"\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html><head><title>Resume Screening Report</title>\n",
        "            <style>\n",
        "                body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 40px; background-color: #f5f5f5; }}\n",
        "                .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 30px; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }}\n",
        "                .header h1 {{ margin: 0; font-size: 32px; }}\n",
        "                .jd-section {{ background: white; padding: 25px; border-radius: 10px; margin-bottom: 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
        "                .candidate {{ background: white; padding: 25px; margin-bottom: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); border-left: 5px solid #667eea; }}\n",
        "                .rank {{ display: inline-block; background: #667eea; color: white; padding: 8px 15px; border-radius: 20px; font-weight: bold; font-size: 18px; }}\n",
        "                .score-container {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 15px; margin: 20px 0; }}\n",
        "                .score-box {{ background: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; border-bottom: 3px solid #667eea; }}\n",
        "                .score-value {{ font-size: 28px; font-weight: bold; color: #667eea; }}\n",
        "                .score-label {{ color: #666; font-size: 14px; margin-top: 5px; }}\n",
        "                .skills {{ display: flex; flex-wrap: wrap; gap: 8px; margin-top: 15px; }}\n",
        "                .skill-tag {{ background: #e3f2fd; color: #1976d2; padding: 5px 12px; border-radius: 15px; font-size: 13px; }}\n",
        "                .info-row {{ display: flex; justify-content: space-between; padding: 10px 0; border-bottom: 1px solid #eee; }}\n",
        "                .info-label {{ font-weight: bold; color: #555; }}\n",
        "            </style>\n",
        "        </head><body>\n",
        "            <div class=\"header\">\n",
        "                <h1>📋 Resume Screening Report</h1>\n",
        "                <p>Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            </div>\n",
        "            <div class=\"jd-section\">\n",
        "                <h2>📄 Job Description Analysis</h2>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">Total Required Skills:</span><span>{len(jd_info['skills']['all_skills'])}</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">Required Experience:</span><span>{jd_info['required_experience']} years</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">Required Education:</span><span>{jd_info['required_education']}</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">Total Candidates Screened:</span><span>{len(all_results_df)}</span></div>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "        for idx, row in results_df.iterrows():\n",
        "            rank = idx + 1\n",
        "            skills_list = row['Skills_List'].split(', ') if row['Skills_List'] else []\n",
        "            skills_html = ''.join([f'<span class=\"skill-tag\">{skill}</span>' for skill in skills_list])\n",
        "            if not skills_html: skills_html = \"<span>No matched skills found.</span>\"\n",
        "            html_content += f\"\"\"\n",
        "            <div class=\"candidate\">\n",
        "                <span class=\"rank\">Rank #{rank}</span>\n",
        "                <h2 style=\"margin-top: 15px;\">{row['Candidate_Name']}</h2>\n",
        "                <p style=\"color: #666;\">{row['Resume']}</p>\n",
        "                <div class=\"score-container\">\n",
        "                    <div class=\"score-box\"><div class=\"score-value\">{row['Composite_Score']:.3f}</div><div class=\"score-label\">Hybrid Score</div></div>\n",
        "                    <div class=\"score-box\"><div class=\"score-value\">{row['Skills_Score']:.3f}</div><div class=\"score-label\">Skills (Jaccard)</div></div>\n",
        "                    <div class=\"score-box\"><div class=\"score-value\">{row['Cosine_Score']:.3f}</div><div class=\"score-label\">Semantic (Cosine)</div></div>\n",
        "                    <div class=\"score-box\"><div class=\"score-value\">{row['Experience_Score']:.3f}</div><div class=\"score-label\">Experience</div></div>\n",
        "                    <div class=\"score-box\"><div class=\"score-value\">{row['Education_Score']:.3f}</div><div class=\"score-label\">Education</div></div>\n",
        "                </div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">📧 Email:</span><span>{row['Email']}</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">📱 Phone:</span><span>{row['Phone']}</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">💼 Experience:</span><span>{row['Total_Years_Experience']} years</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">🎓 Education:</span><span>{row['Highest_Degree']}</span></div>\n",
        "                <div class=\"info-row\"><span class=\"info-label\">✅ Skills Match:</span><span>{row['Matched_Skills']} of {row['Total_JD_Skills']} ({row['Match_Percentage']:.1f}%)</span></div>\n",
        "                <h3 style=\"margin-top: 20px;\">Matched Skills:</h3>\n",
        "                <div class=\"skills\">{skills_html}</div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        html_content += \"\"\"</body></html>\"\"\"\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "        print(f\"✓ HTML report saved to {output_file}\")\n",
        "\n",
        "    # ---\n",
        "    # --- NEW FUNCTION TO REPLICATE YOUR PAPER'S EVALUATION ---\n",
        "    # ---\n",
        "    def evaluate_extraction_accuracy(self, resume_folder, ground_truth_file):\n",
        "        \"\"\"\n",
        "        Evaluates skill extraction accuracy against a manual ground truth file.\n",
        "        This is a \"meta-analysis\" function and is not part of the core screening.\n",
        "\n",
        "        :param resume_folder: Path to the folder with PDF resumes.\n",
        "        :param ground_truth_file: Path to a JSON file with the format:\n",
        "                                  { \"resume_filename.pdf\": [\"skill1\", \"skill2\", ...], ... }\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PERFORMING SKILL EXTRACTION EVALUATION (from Section 4.3.2)\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            with open(ground_truth_file, 'r') as f:\n",
        "                ground_truth = json.load(f)\n",
        "            print(f\"Loaded ground truth for {len(ground_truth)} resumes from '{ground_truth_file}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Could not load ground truth file '{ground_truth_file}'. {e}\")\n",
        "            print(\"Evaluation aborted. Please create this file to run the evaluation.\")\n",
        "            return\n",
        "\n",
        "        total_correctly_extracted = 0\n",
        "        total_ground_truth_skills = 0\n",
        "\n",
        "        for filename, true_skills in ground_truth.items():\n",
        "            pdf_path = os.path.join(resume_folder, filename)\n",
        "            if not os.path.exists(pdf_path):\n",
        "                print(f\"Warning: {filename} from ground truth not found in resume folder. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Extract text and skills using the script's functions\n",
        "            text = self.extract_text_from_pdf(pdf_path)\n",
        "            if not text:\n",
        "                print(f\"Warning: Could not read {filename}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            extracted_skills_data = self.extract_skills(text)\n",
        "            extracted_skills = set([s.lower() for s in extracted_skills_data['all_skills']])\n",
        "\n",
        "            # Compare to ground truth\n",
        "            true_skills_set = set([s.lower() for s in true_skills])\n",
        "            correctly_extracted = extracted_skills.intersection(true_skills_set)\n",
        "\n",
        "            total_correctly_extracted += len(correctly_extracted)\n",
        "            total_ground_truth_skills += len(true_skills_set)\n",
        "\n",
        "            # Optional: Per-file accuracy\n",
        "            # accuracy = (len(correctly_extracted) / len(true_skills_set)) * 100 if len(true_skills_set) > 0 else 0\n",
        "            # print(f\"  -> Evaluating: {filename} - Found {len(correctly_extracted)} of {len(true_skills_set)} skills. ({accuracy:.1f}%)\")\n",
        "\n",
        "        if total_ground_truth_skills == 0:\n",
        "            print(\"No ground truth skills were found to evaluate against.\")\n",
        "            return\n",
        "\n",
        "        overall_accuracy = (total_correctly_extracted / total_ground_truth_skills) * 100\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"Overall Skill Extraction Accuracy Results:\")\n",
        "        print(f\"  Total Skills in Ground Truth (all files): {total_ground_truth_skills}\")\n",
        "        print(f\"  Total Skills Correctly Extracted:         {total_correctly_extracted}\")\n",
        "        print(f\"  OVERALL ACCURACY:                         {overall_accuracy:.2f}%\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        return overall_accuracy\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the advanced resume screening system\"\"\"\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'ADVANCED RESUME SCREENING SYSTEM':^100}\")\n",
        "    print(f\"{'with TF-IDF, NER, Experience Extraction & Visualization':^100}\")\n",
        "    print(\"=\"*100)\n",
        "    print()\n",
        "\n",
        "    # Initialize screener\n",
        "    # --- Make sure to use the correct path for your Colab environment ---\n",
        "    SKILLS_DB_PATH = '/content/drive/MyDrive/CDS_PROJECT/skills_db.json'\n",
        "    screener = AdvancedResumeScreener(skills_db_path=SKILLS_DB_PATH)\n",
        "\n",
        "    # Example job description (from your prompt)\n",
        "    default_jd = \"\"\"\n",
        "    Data Analyst\n",
        "\n",
        "    We are looking for a Data Analyst.\n",
        "    - Experience with SQL and databases like PostgreSQL or MySQL.\n",
        "    - Strong skills in data visualization tools like Tableau and Power BI.\n",
        "    - Proficient in Python, particularly with libraries like Pandas and Numpy.\n",
        "    - Knowledge of data analysis and statistical models.\n",
        "    - Good communication and teamwork skills.\n",
        "    - Bachelor's degree in a related field.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get inputs\n",
        "    print(\"=\" * 100)\n",
        "    print(\"STEP 1: JOB DESCRIPTION\")\n",
        "    print(\"=\" * 100)\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. Use default job description (Data Analyst)\")\n",
        "    print(\"2. Enter custom job description\")\n",
        "    print(\"3. Load from file\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1/2/3) [default: 1]: \").strip()\n",
        "    if choice == '2':\n",
        "        print(\"\\nEnter job description (press Ctrl+D on Linux/macOS or Ctrl+Z+Enter on Windows when done):\")\n",
        "        job_description = \"\"\n",
        "        try:\n",
        "            while True:\n",
        "                line = input()\n",
        "                job_description += line + \"\\n\"\n",
        "        except EOFError:\n",
        "            pass\n",
        "    elif choice == '3':\n",
        "        jd_file = input(\"Enter path to job description file: \").strip()\n",
        "        try:\n",
        "            with open(jd_file, 'r', encoding='utf-8') as f:\n",
        "                job_description = f.read()\n",
        "        except:\n",
        "            print(\"Error reading file. Using default JD.\")\n",
        "            job_description = default_jd\n",
        "    else:\n",
        "        job_description = default_jd\n",
        "\n",
        "    # Get resume folder\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 2: RESUME FOLDER\")\n",
        "    print(\"=\" * 100)\n",
        "    resume_folder = input(\"\\nEnter path to resume folder [default: ./resumes]: \").strip()\n",
        "    if not resume_folder:\n",
        "        resume_folder = \"/content/drive/MyDrive/CDS_PROJECT/Resumes\" # Defaulting to your Colab path\n",
        "    if not os.path.exists(resume_folder):\n",
        "        print(f\"\\nFolder '{resume_folder}' not found! Please check the path.\")\n",
        "        return\n",
        "\n",
        "    # Get top N\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 3: SCREENING PARAMETERS\")\n",
        "    print(\"=\" * 100)\n",
        "    top_n_input = input(\"\\nEnter number of top candidates to shortlist [default: 5]: \").strip()\n",
        "    top_n = int(top_n_input) if top_n_input.isdigit() and int(top_n_input) > 0 else 5\n",
        "\n",
        "    # --- MODIFIED WEIGHTS SECTION ---\n",
        "    # Now defaults to the formula from your paper\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 4: SCORING WEIGHTS\")\n",
        "    print(\"=\" * 100)\n",
        "    print(\"\\nUse custom scoring weights?\")\n",
        "    print(\"Default is based on your paper (0.6 * Cosine + 0.4 * Jaccard/Skills).\")\n",
        "    custom_weights = input(\"(y/n) [default: n]: \").strip().lower()\n",
        "\n",
        "    weights = None\n",
        "    if custom_weights == 'y':\n",
        "        print(\"\\nEnter weights (must sum to 1.0):\")\n",
        "        try:\n",
        "            skills_w = float(input(\"  Skills (Jaccard) weight [default: 0.4]: \") or 0.4)\n",
        "            cosine_w = float(input(\"  Semantic (Cosine) weight [default: 0.6]: \") or 0.6)\n",
        "            exp_w = float(input(\"  Experience weight [default: 0.0]: \") or 0.0)\n",
        "            edu_w = float(input(\"  Education weight [default: 0.0]: \") or 0.0)\n",
        "\n",
        "            total_w = skills_w + cosine_w + exp_w + edu_w\n",
        "            if abs(total_w - 1.0) < 0.01:\n",
        "                weights = {'skills': skills_w, 'cosine': cosine_w, 'experience': exp_w, 'education': edu_w}\n",
        "                print(f\"Using custom weights. Total: {total_w}\")\n",
        "            else:\n",
        "                print(f\"Weights sum to {total_w}, not 1.0. Using defaults from paper.\")\n",
        "                weights = {'skills': 0.4, 'cosine': 0.6}\n",
        "        except:\n",
        "            print(\"Invalid input. Using default weights from paper.\")\n",
        "            weights = {'skills': 0.4, 'cosine': 0.6}\n",
        "    else:\n",
        "         print(\"✓ Using default weights from paper (0.6 * Cosine + 0.4 * Jaccard).\")\n",
        "         weights = {'skills': 0.4, 'cosine': 0.6}\n",
        "\n",
        "    # --- END OF MODIFIED SECTION ---\n",
        "\n",
        "    # Process resumes\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"PROCESSING RESUMES...\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\", UserWarning)\n",
        "        top_results, jd_info, all_results = screener.screen_resumes(job_description, resume_folder, top_n, weights)\n",
        "\n",
        "    if top_results.empty:\n",
        "        print(\"\\n❌ No resumes could be processed!\")\n",
        "        return\n",
        "\n",
        "    # Display results\n",
        "    screener.display_results(top_results, jd_info)\n",
        "\n",
        "    # Save results\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"SAVING RESULTS...\")\n",
        "    print(\"=\" * 100)\n",
        "    screener.save_results(all_results, 'screening_results.csv') # Save all results\n",
        "\n",
        "    # Generate HTML report\n",
        "    screener.generate_report(top_results, jd_info, all_results, 'screening_report.html')\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"GENERATING VISUALIZATIONS...\")\n",
        "    print(\"=\" * 100)\n",
        "    visualize = input(\"\\nGenerate visualizations? (y/n) [default: y]: \").strip().lower()\n",
        "    if visualize != 'n':\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\", UserWarning)\n",
        "            screener.visualize_results(all_results, jd_info, 'visualizations')\n",
        "\n",
        "    # ---\n",
        "    # --- NEW (OPTIONAL) STEP: RUN EVALUATION ---\n",
        "    # ---\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"STEP 5: EVALUATE ACCURACY (from Section 4.3.2)\")\n",
        "    print(\"=\" * 100)\n",
        "    run_eval = input(\"\\nRun skill extraction accuracy evaluation? (y/n) [default: n]: \").strip().lower()\n",
        "    if run_eval == 'y':\n",
        "        ground_truth_path = input(\"  Enter path to ground_truth.json file: \").strip()\n",
        "        if not ground_truth_path:\n",
        "             ground_truth_path = \"/content/drive/MyDrive/CDS_PROJECT/ground_truth.json\" # Example\n",
        "\n",
        "        screener.evaluate_extraction_accuracy(resume_folder, ground_truth_path)\n",
        "    # --- END OF NEW STEP ---\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\"{'✓ SCREENING COMPLETED SUCCESSFULLY!':^100}\")\n",
        "    print(\"=\"*100)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(\"  📊 screening_results.csv - Detailed results for ALL candidates\")\n",
        "    print(\"  📄 screening_report.html - Interactive report of TOP candidates\")\n",
        "    if visualize != 'n':\n",
        "        print(\"  📈 visualizations/ - Folder containing all charts and graphs\")\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Iusm4y7F5M9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8879874-68f8-4667-97e5-6358fdb0d6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK package: punkt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK package: punkt_tab...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK package: stopwords...\n",
            "Downloading NLTK package: wordnet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK package: omw-1.4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "                                  ADVANCED RESUME SCREENING SYSTEM                                  \n",
            "                      with TF-IDF, NER, Experience Extraction & Visualization                       \n",
            "====================================================================================================\n",
            "\n",
            "Loading skills database from /content/drive/MyDrive/CDS_PROJECT/skills_db.json...\n",
            "====================================================================================================\n",
            "STEP 1: JOB DESCRIPTION\n",
            "====================================================================================================\n",
            "\n",
            "Options:\n",
            "1. Use default job description (Data Analyst)\n",
            "2. Enter custom job description\n",
            "3. Load from file\n",
            "\n",
            "Enter your choice (1/2/3) [default: 1]: 1\n",
            "\n",
            "====================================================================================================\n",
            "STEP 2: RESUME FOLDER\n",
            "====================================================================================================\n",
            "\n",
            "Enter path to resume folder [default: ./resumes]: /content/drive/MyDrive/CDS_PROJECT/Resumes\n",
            "\n",
            "====================================================================================================\n",
            "STEP 3: SCREENING PARAMETERS\n",
            "====================================================================================================\n",
            "\n",
            "Enter number of top candidates to shortlist [default: 5]: 2\n",
            "\n",
            "====================================================================================================\n",
            "STEP 4: SCORING WEIGHTS\n",
            "====================================================================================================\n",
            "\n",
            "Use custom scoring weights?\n",
            "Default is based on your paper (0.6 * Cosine + 0.4 * Jaccard/Skills).\n",
            "(y/n) [default: n]: N\n",
            "✓ Using default weights from paper (0.6 * Cosine + 0.4 * Jaccard).\n",
            "\n",
            "====================================================================================================\n",
            "PROCESSING RESUMES...\n",
            "====================================================================================================\n",
            "Parsing Job Description...\n",
            "\n",
            "================================================================================\n",
            "JOB DESCRIPTION ANALYSIS\n",
            "================================================================================\n",
            "Required Skills: 12\n",
            "Skills: power bi, teamwork, postgresql, mysql, tableau, python, pandas, data visualization, numpy, communication...\n",
            "Required Experience: 0 years\n",
            "Required Education: Bachelors\n",
            "================================================================================\n",
            "\n",
            "Processing 5 resumes...\n",
            "\n",
            "Analyzing 1/5: Om_Patel_CV.pdf\n",
            "Analyzing 2/5: VED_CV.docx.pdf\n",
            "Analyzing 3/5: Het_Resume_NEW.pdf\n",
            "Analyzing 4/5: Stuti-Resume.pdf\n",
            "Analyzing 5/5: Dilon Resume.pdf\n",
            "\n",
            "====================================================================================================\n",
            "                                    TOP 2 SHORTLISTED CANDIDATES                                    \n",
            "====================================================================================================\n",
            "\n",
            "                                              RANK #1                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Gohil\n",
            "+91\n",
            "Resume File:              Stuti-Resume.pdf\n",
            "Email:                    sng19.work@gmail.com\n",
            "Phone:                    +91 6355046464\n",
            "\n",
            "SCORES:                  \n",
            "  Hybrid Score:           0.1150 (11.5%)\n",
            "  Skills (Jaccard) Score: 0.1818 (18.2%)\n",
            "  Semantic (Cosine) Score: 0.0704 (7.0%)\n",
            "\n",
            "OTHER METRICS (for info):\n",
            "  Experience Score:       0.7200 (72.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             3.6 years (JD: 0 yrs)\n",
            "  Education:              Masters (JD: Bachelors)\n",
            "  Matched Skills:         6 of 12 (50.0%)\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          power bi, python, pandas, numpy, communication\n",
            "                          sql\n",
            "\n",
            "                                              RANK #2                                               \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidate:                Samaj\n",
            "Resume File:              Het_Resume_NEW.pdf\n",
            "Email:                    hetvirani1305@gmail.com\n",
            "Phone:                    +91-9313917798\n",
            "\n",
            "SCORES:                  \n",
            "  Hybrid Score:           0.1147 (11.5%)\n",
            "  Skills (Jaccard) Score: 0.2353 (23.5%)\n",
            "  Semantic (Cosine) Score: 0.0343 (3.4%)\n",
            "\n",
            "OTHER METRICS (for info):\n",
            "  Experience Score:       0.0400 (4.0%)\n",
            "  Education Score:        1.0000 (100.0%)\n",
            "\n",
            "QUALIFICATIONS:          \n",
            "  Experience:             0.2 years (JD: 0 yrs)\n",
            "  Education:              Masters (JD: Bachelors)\n",
            "  Matched Skills:         4 of 12 (33.3%)\n",
            "\n",
            "MATCHED SKILLS:          \n",
            "                          mysql, teamwork, communication, postgresql\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "SAVING RESULTS...\n",
            "====================================================================================================\n",
            "✓ Results saved to screening_results.csv\n",
            "✓ HTML report saved to screening_report.html\n",
            "\n",
            "====================================================================================================\n",
            "GENERATING VISUALIZATIONS...\n",
            "====================================================================================================\n",
            "\n",
            "Generate visualizations? (y/n) [default: y]: y\n",
            "✓ Saved: visualizations/1_composite_scores.png\n",
            "✓ Saved: visualizations/2_score_breakdown.png\n",
            "✓ Saved: visualizations/3_skills_match.png\n",
            "✓ Saved: visualizations/4_experience_vs_score.png\n",
            "✓ Saved: visualizations/5_education_distribution.png\n",
            "✓ Saved: visualizations/6_radar_chart.png\n",
            "\n",
            "✓ All visualizations saved in 'visualizations' folder!\n",
            "\n",
            "====================================================================================================\n",
            "STEP 5: EVALUATE ACCURACY (from Section 4.3.2)\n",
            "====================================================================================================\n",
            "\n",
            "Run skill extraction accuracy evaluation? (y/n) [default: n]: y\n",
            "  Enter path to ground_truth.json file: /content/drive/MyDrive/CDS_PROJECT/ground_truth_example.json\n",
            "\n",
            "================================================================================\n",
            "PERFORMING SKILL EXTRACTION EVALUATION (from Section 4.3.2)\n",
            "================================================================================\n",
            "Loaded ground truth for 3 resumes from '/content/drive/MyDrive/CDS_PROJECT/ground_truth_example.json'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Overall Skill Extraction Accuracy Results:\n",
            "  Total Skills in Ground Truth (all files): 31\n",
            "  Total Skills Correctly Extracted:         19\n",
            "  OVERALL ACCURACY:                         61.29%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====================================================================================================\n",
            "                                ✓ SCREENING COMPLETED SUCCESSFULLY!                                 \n",
            "====================================================================================================\n",
            "\n",
            "Generated Files:\n",
            "  📊 screening_results.csv - Detailed results for ALL candidates\n",
            "  📄 screening_report.html - Interactive report of TOP candidates\n",
            "  📈 visualizations/ - Folder containing all charts and graphs\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **/content/drive/MyDrive/CDS_PROJECT/ground_truth_example.json**"
      ],
      "metadata": {
        "id": "A45YAeaszph3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\n",
        "  \"Stuti-Resume.pdf\": [\n",
        "    \"Python\",\n",
        "    \"Machine Learning\",\n",
        "    \"TensorFlow\",\n",
        "    \"PyTorch\",\n",
        "    \"SQL\",\n",
        "    \"Git\",\n",
        "    \"Docker\",\n",
        "    \"AWS\",\n",
        "    \"GCP\",\n",
        "    \"Agile\",\n",
        "    \"Scrum\",\n",
        "    \"Communication\",\n",
        "    \"CI/CD\",\n",
        "    \"scikit-learn\"\n",
        "  ],\n",
        "  \"Om_Patel_CV.pdf\": [\n",
        "    \"Python\",\n",
        "    \"C++\",\n",
        "    \"Java\",\n",
        "    \"React\",\n",
        "    \"Node.js\",\n",
        "    \"MySQL\",\n",
        "    \"MongoDB\",\n",
        "    \"Git\",\n",
        "    \"Communication\"\n",
        "  ],\n",
        "  \"Het_Resume_NEW.pdf\": [\n",
        "    \"Python\",\n",
        "    \"Pandas\",\n",
        "    \"Numpy\",\n",
        "    \"SQL\",\n",
        "    \"Tableau\",\n",
        "    \"Power BI\",\n",
        "    \"Excel\",\n",
        "    \"Data Analysis\"\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "-pr1aAZuzpbh"
      }
    }
  ]
}